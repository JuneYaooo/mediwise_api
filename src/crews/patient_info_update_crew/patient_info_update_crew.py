import os
from dotenv import load_dotenv
load_dotenv()
from crewai import Agent, Crew, Process, Task, LLM
from crewai.project import CrewBase, agent, crew, task
from src.llms import *
from src.utils.json_utils import JsonUtils
from src.utils.logger import BeijingLogger
from datetime import datetime
import time
import json
import uuid
import copy
import re
from typing import Dict, List, Any, Optional
from pathlib import Path

# ğŸ†• Tokenç®¡ç†å’Œæ•°æ®å‹ç¼©æ¨¡å—
from src.utils.token_manager import TokenManager
from src.utils.data_compressor import PatientDataCompressor

# åˆå§‹åŒ– logger
logger = BeijingLogger().get_logger()

@CrewBase
class PatientInfoUpdateCrew():
    """ç®€åŒ–çš„æ‚£è€…ä¿¡æ¯æ›´æ–°crewï¼Œä¸“æ³¨äºåˆ†æå’Œä¿®æ”¹æ“ä½œ"""

    agents_config = "config/agents.yaml"
    tasks_config = "config/tasks.yaml"
    
    def __init__(self):
        """
        åˆå§‹åŒ–PatientInfoUpdateCrew
        """
        pass
    
    def _execute_modifications(self, patient_data: Dict, modifications: List[Dict]) -> Dict:
        """
        æ ¹æ®ä¿®æ”¹æŒ‡ä»¤æ‰§è¡Œå…·ä½“çš„ä¿®æ”¹æ“ä½œï¼Œæ”¯æŒå¤æ‚çš„å¤šå¤„ä¿®æ”¹
        
        Args:
            patient_data: å½“å‰çš„æ‚£è€…æ•°æ®
            modifications: ä¿®æ”¹æŒ‡ä»¤åˆ—è¡¨ï¼ŒæŒ‰sequenceæ’åº
            
        Returns:
            ä¿®æ”¹åçš„æ‚£è€…æ•°æ®
        """
        try:
            # æ·±æ‹·è´æ•°æ®ï¼Œé¿å…ä¿®æ”¹åŸå§‹æ•°æ®
            updated_data = copy.deepcopy(patient_data)
            
            # æŒ‰sequenceæ’åºæ‰§è¡Œä¿®æ”¹
            sorted_modifications = sorted(modifications, key=lambda x: x.get("sequence", 0))
            
            for mod in sorted_modifications:
                target_module = mod.get("target_module", "")
                target_path = mod.get("target_path", "")
                action = mod.get("action", "")
                new_value = mod.get("new_value")
                condition = mod.get("condition")
                leading_context = mod.get("leading_context")
                target_content = mod.get("target_content")
                trailing_context = mod.get("trailing_context")
                description = mod.get("description", "")
                sequence = mod.get("sequence", 0)
                reason = mod.get("reason", "")
                
                logger.info(f"æ‰§è¡Œä¿®æ”¹ #{sequence}: {description} - {reason}")
                
                # æ ¹æ®ç›®æ ‡æ¨¡å—è·å–æ•°æ®
                if target_module == "patient_timeline":
                    target_data = updated_data.get("patient_timeline", {})
                elif target_module == "patient_journey":
                    target_data = updated_data.get("patient_journey", {})
                elif target_module == "mdt_simple_report":
                    target_data = updated_data.get("mdt_simple_report", [])
                else:
                    logger.warning(f"æœªçŸ¥çš„ç›®æ ‡æ¨¡å—: {target_module}")
                    continue
                
                # æ¸…ç†è·¯å¾„ï¼šå¦‚æœè·¯å¾„ä»¥æ¨¡å—åå¼€å¤´ï¼Œå»é™¤æ¨¡å—åå‰ç¼€
                # ä¾‹å¦‚: "mdt_simple_report[12].rows[0][3]" -> "[12].rows[0][3]"
                logger.info(f"ğŸ” åŸå§‹è·¯å¾„: {target_path}, ç›®æ ‡æ¨¡å—: {target_module}")
                clean_path = target_path
                if target_path.startswith(f"{target_module}."):
                    clean_path = target_path[len(target_module) + 1:]  # +1 æ˜¯ä¸ºäº†å»æ‰ç‚¹å·
                    logger.info(f"âœ‚ï¸ æ¸…ç†è·¯å¾„å‰ç¼€ï¼ˆç‚¹å·ï¼‰: {target_path} -> {clean_path}")
                elif target_path.startswith(f"{target_module}["):
                    clean_path = target_path[len(target_module):]  # ä¿ç•™ [ å·
                    logger.info(f"âœ‚ï¸ æ¸…ç†è·¯å¾„å‰ç¼€ï¼ˆæ‹¬å·ï¼‰: {target_path} -> {clean_path}")
                else:
                    logger.info(f"âš ï¸ è·¯å¾„ä¸éœ€è¦æ¸…ç†: {target_path}")
                
                logger.info(f"ğŸ“ æœ€ç»ˆä½¿ç”¨çš„è·¯å¾„: {clean_path}")
                logger.info(f"ğŸ“¦ ç›®æ ‡æ•°æ®ç±»å‹: {type(target_data).__name__}, é•¿åº¦/é”®: {len(target_data) if isinstance(target_data, (list, dict)) else 'N/A'}")
                
                # æ‰§è¡Œå…·ä½“çš„ä¿®æ”¹æ“ä½œï¼ˆä½¿ç”¨æ¸…ç†åçš„è·¯å¾„ï¼‰
                if action == "set":
                    # ç›´æ¥è®¾ç½®å­—æ®µå€¼
                    self._set_value_by_path(target_data, clean_path, new_value)
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦å…³è”æ›´æ–°ï¼ˆå¦‚æŒ‡æ ‡å¼‚å¸¸çŠ¶æ€ï¼‰
                    self._check_and_update_related_fields(target_data, clean_path, new_value)
                elif action == "modify_text":
                    # åŸºäºå‰å¯¼ä¸Šä¸‹æ–‡çš„æ–‡æœ¬ä¿®æ”¹
                    self._modify_text_by_path(target_data, clean_path, new_value, 
                                            leading_context, target_content, trailing_context)
                elif action == "delete":
                    # åˆ é™¤æ“ä½œä¿ç•™ï¼Œç”¨äºåˆ é™¤æ•´ä¸ªæ¡ç›®
                    self._delete_value_by_path(target_data, clean_path)
                else:
                    logger.warning(f"æœªçŸ¥çš„æ“ä½œç±»å‹: {action}ï¼Œæ”¯æŒçš„æ“ä½œç±»å‹: set, modify_text, delete")
                
                # å°†ä¿®æ”¹åçš„æ•°æ®å†™å›
                if target_module == "patient_timeline":
                    updated_data["patient_timeline"] = target_data
                elif target_module == "patient_journey":
                    updated_data["patient_journey"] = target_data
                elif target_module == "mdt_simple_report":
                    updated_data["mdt_simple_report"] = target_data
            
            return updated_data
            
        except Exception as e:
            logger.error(f"æ‰§è¡Œä¿®æ”¹æ“ä½œæ—¶å‡ºé”™: {e}")
            logger.error(f"é”™è¯¯ç±»å‹: {type(e)}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return patient_data
    
    def _update_value(self, target_data: Any, path: str, new_value: Any, condition: Dict = None):
        """æ›´æ–°å€¼ï¼Œå·²åºŸå¼ƒï¼Œä½¿ç”¨ç®€åŒ–çš„æ–¹æ³•æ›¿ä»£"""
        logger.warning("_update_valueæ–¹æ³•å·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨setæˆ–modify_textæ“ä½œ")
        self._set_value_by_path(target_data, path, new_value)
    
    def _set_value(self, target_data: Any, path: str, new_value: Any, condition: Dict = None):
        """è®¾ç½®å€¼ï¼Œå·²åºŸå¼ƒï¼Œä½¿ç”¨ç®€åŒ–çš„æ–¹æ³•æ›¿ä»£"""
        logger.warning("_set_valueæ–¹æ³•å·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨setæ“ä½œ")
        self._set_value_by_path(target_data, path, new_value)
    
    def _delete_value(self, target_data: Any, path: str, condition: Dict = None):
        """åˆ é™¤å€¼ï¼Œå·²åºŸå¼ƒï¼Œä½¿ç”¨ç®€åŒ–çš„æ–¹æ³•æ›¿ä»£"""
        logger.warning("_delete_valueæ–¹æ³•å·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨deleteæ“ä½œ")
        self._delete_value_by_path(target_data, path)
    
    def _append_value(self, target_data: Any, path: str, new_value: Any):
        """è¿½åŠ å€¼ï¼Œå·²åºŸå¼ƒ"""
        logger.warning("_append_valueæ–¹æ³•å·²åºŸå¼ƒ")
    
    def _insert_value(self, target_data: Any, path: str, new_value: Any, condition: Dict = None):
        """æ’å…¥å€¼ï¼Œå·²åºŸå¼ƒ"""
        logger.warning("_insert_valueæ–¹æ³•å·²åºŸå¼ƒ")
    
    def _parse_path_to_tokens(self, path: str) -> List[str]:
        """å°†è·¯å¾„è§£æä¸ºæ ‡å‡†åŒ–çš„tokenåˆ—è¡¨

        ä¾‹å¦‚ï¼š
        - "[12].rows[4][3]" -> ["[12]", "rows", "[4]", "[3]"]
        - "key.array[0].field" -> ["key", "array", "[0]", "field"]
        - "rows[4][3]" -> ["rows", "[4]", "[3]"]
        """
        tokens = []

        # å…ˆæŒ‰ç‚¹åˆ†å‰²
        parts = path.split('.')

        for part in parts:
            if not part:
                continue

            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ•°ç»„ç´¢å¼•
            if '[' not in part:
                # æ™®é€šé”®
                tokens.append(part)
            else:
                # åŒ…å«æ•°ç»„ç´¢å¼•ï¼Œéœ€è¦è¿›ä¸€æ­¥è§£æ
                # ä¾‹å¦‚ "rows[4][3]" -> ["rows", "[4]", "[3]"]
                # ä¾‹å¦‚ "[12]" -> ["[12]"]
                current_pos = 0
                while current_pos < len(part):
                    bracket_start = part.find('[', current_pos)

                    if bracket_start == -1:
                        # æ²¡æœ‰æ›´å¤šçš„æ‹¬å·
                        if current_pos < len(part):
                            remaining = part[current_pos:]
                            if remaining:
                                tokens.append(remaining)
                        break

                    # å…ˆæ·»åŠ æ‹¬å·å‰çš„éƒ¨åˆ†ï¼ˆå¦‚æœæœ‰ï¼‰
                    if bracket_start > current_pos:
                        prefix = part[current_pos:bracket_start]
                        if prefix:
                            tokens.append(prefix)

                    # æ‰¾åˆ°å¯¹åº”çš„å³æ‹¬å·
                    bracket_end = part.find(']', bracket_start)
                    if bracket_end == -1:
                        logger.error(f"è·¯å¾„æ ¼å¼é”™è¯¯ï¼Œç¼ºå°‘å³æ‹¬å·: {part}")
                        break

                    # æ·»åŠ æ•°ç»„ç´¢å¼• tokenï¼ˆåŒ…æ‹¬æ‹¬å·ï¼‰
                    index_token = part[bracket_start:bracket_end + 1]
                    tokens.append(index_token)

                    current_pos = bracket_end + 1

        return tokens

    def _set_value_by_path(self, target_data: Any, path: str, new_value: Any):
        """é€šè¿‡è·¯å¾„è®¾ç½®å€¼ - æ ¸å¿ƒæ–¹æ³•

        æ”¯æŒçš„è·¯å¾„æ ¼å¼ï¼š
        - "key1.key2.key3": åµŒå¥—å­—å…¸è®¿é—®
        - "array[0]": æ•°ç»„ç´¢å¼•è®¿é—®
        - "[0].key": ä»æ•°ç»„å¼€å§‹çš„è·¯å¾„
        - "key.array[0].key2": æ··åˆè®¿é—®
        - "rows[4][3]": è¿ç»­æ•°ç»„ç´¢å¼•
        """
        try:
            logger.info(f"ğŸ”§ _set_value_by_path è¢«è°ƒç”¨")
            logger.info(f"   - è·¯å¾„: {path}")
            logger.info(f"   - æ–°å€¼: {new_value}")
            logger.info(f"   - æ•°æ®ç±»å‹: {type(target_data).__name__}")

            # ä½¿ç”¨æ–°çš„è·¯å¾„è§£ææ–¹æ³•
            tokens = self._parse_path_to_tokens(path)
            logger.info(f"   - è·¯å¾„token: {tokens}")

            if not tokens:
                logger.error("è·¯å¾„è§£æç»“æœä¸ºç©º")
                return

            current = target_data

            # éå†åˆ°å€’æ•°ç¬¬äºŒå±‚
            for token in tokens[:-1]:
                current = self._navigate_by_token(current, token)
                if current is None:
                    return

            # è®¾ç½®æœ€åä¸€å±‚çš„å€¼
            final_token = tokens[-1]
            self._set_final_value_by_token(current, final_token, new_value)

            logger.info(f"âœ“ æˆåŠŸè®¾ç½®è·¯å¾„ {path} çš„å€¼ä¸º: {new_value}")

        except Exception as e:
            logger.error(f"é€šè¿‡è·¯å¾„è®¾ç½®å€¼æ—¶å‡ºé”™ - è·¯å¾„: {path}, æ–°å€¼: {new_value}, é”™è¯¯: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")

    def _navigate_by_token(self, current: Any, token: str) -> Any:
        """æ ¹æ®å•ä¸ªtokenå¯¼èˆª

        Args:
            current: å½“å‰æ•°æ®èŠ‚ç‚¹
            token: è·¯å¾„tokenï¼Œä¾‹å¦‚ "key", "[0]"

        Returns:
            å¯¼èˆªåçš„æ•°æ®èŠ‚ç‚¹ï¼Œå¤±è´¥è¿”å› None
        """
        if token.startswith('[') and token.endswith(']'):
            # çº¯æ•°ç»„ç´¢å¼•
            try:
                index = int(token[1:-1])
            except ValueError:
                logger.error(f"æ— æ•ˆçš„æ•°ç»„ç´¢å¼•: {token}")
                return None

            if not isinstance(current, list):
                logger.error(f"æœŸæœ›æ•°ç»„ä½†å¾—åˆ° {type(current).__name__}")
                return None
            if index >= len(current):
                logger.error(f"æ•°ç»„ç´¢å¼• {index} è¶…å‡ºèŒƒå›´ï¼ˆé•¿åº¦: {len(current)}ï¼‰")
                return None
            return current[index]
        else:
            # æ™®é€šé”®è®¿é—®
            if not isinstance(current, dict):
                logger.error(f"æœŸæœ›å­—å…¸ä½†å¾—åˆ° {type(current).__name__}")
                return None
            if token not in current:
                logger.error(f"é”® '{token}' ä¸å­˜åœ¨äºå½“å‰æ•°æ®ä¸­")
                return None
            return current[token]

    def _set_final_value_by_token(self, current: Any, token: str, new_value: Any):
        """æ ¹æ®å•ä¸ªtokenè®¾ç½®æœ€ç»ˆå€¼

        Args:
            current: å½“å‰æ•°æ®èŠ‚ç‚¹
            token: è·¯å¾„tokenï¼Œä¾‹å¦‚ "key", "[0]"
            new_value: è¦è®¾ç½®çš„æ–°å€¼
        """
        if token.startswith('[') and token.endswith(']'):
            # çº¯æ•°ç»„ç´¢å¼•
            try:
                index = int(token[1:-1])
            except ValueError:
                logger.error(f"æ— æ•ˆçš„æ•°ç»„ç´¢å¼•: {token}")
                return

            if not isinstance(current, list):
                logger.error(f"æœŸæœ›æ•°ç»„ä½†å¾—åˆ° {type(current).__name__}")
                return
            if index >= len(current):
                logger.error(f"æ•°ç»„ç´¢å¼• {index} è¶…å‡ºèŒƒå›´ï¼ˆé•¿åº¦: {len(current)}ï¼‰")
                return
            current[index] = new_value
        else:
            # æ™®é€šé”®èµ‹å€¼
            if not isinstance(current, dict):
                logger.error(f"æœŸæœ›å­—å…¸ä½†å¾—åˆ° {type(current).__name__}")
                return
            current[token] = new_value
    
    def _navigate_to_part(self, current: Any, part: str) -> Any:
        """å¯¼èˆªåˆ°è·¯å¾„çš„æŸä¸ªéƒ¨åˆ†
        
        Args:
            current: å½“å‰æ•°æ®èŠ‚ç‚¹
            part: è·¯å¾„éƒ¨åˆ†ï¼Œä¾‹å¦‚ "key", "array[0]", "[0]"
            
        Returns:
            å¯¼èˆªåçš„æ•°æ®èŠ‚ç‚¹ï¼Œå¤±è´¥è¿”å› None
        """
        if '[' in part and ']' in part:
            # å¤„ç†æ•°ç»„ç´¢å¼•
            key = part.split('[')[0]
            index = int(part.split('[')[1].split(']')[0])
            
            if key == '':
                # çº¯æ•°ç»„ç´¢å¼•ï¼Œä¾‹å¦‚ "[0]"
                if not isinstance(current, list):
                    logger.error(f"æœŸæœ›æ•°ç»„ä½†å¾—åˆ° {type(current).__name__}")
                    return None
                if index >= len(current):
                    logger.error(f"æ•°ç»„ç´¢å¼• {index} è¶…å‡ºèŒƒå›´ï¼ˆé•¿åº¦: {len(current)}ï¼‰")
                    return None
                return current[index]
            else:
                # é”®å + æ•°ç»„ç´¢å¼•ï¼Œä¾‹å¦‚ "rows[0]"
                if not isinstance(current, dict):
                    logger.error(f"æœŸæœ›å­—å…¸ä½†å¾—åˆ° {type(current).__name__}")
                    return None
                if key not in current:
                    logger.error(f"é”® '{key}' ä¸å­˜åœ¨äºå½“å‰æ•°æ®ä¸­")
                    return None
                if not isinstance(current[key], list):
                    logger.error(f"'{key}' ä¸æ˜¯æ•°ç»„")
                    return None
                if index >= len(current[key]):
                    logger.error(f"æ•°ç»„ '{key}' çš„ç´¢å¼• {index} è¶…å‡ºèŒƒå›´ï¼ˆé•¿åº¦: {len(current[key])}ï¼‰")
                    return None
                return current[key][index]
        else:
            # æ™®é€šé”®è®¿é—®
            if not isinstance(current, dict):
                logger.error(f"æœŸæœ›å­—å…¸ä½†å¾—åˆ° {type(current).__name__}")
                return None
            if part not in current:
                logger.error(f"é”® '{part}' ä¸å­˜åœ¨äºå½“å‰æ•°æ®ä¸­")
                return None
            return current[part]
    
    def _set_final_value(self, current: Any, final_part: str, new_value: Any):
        """è®¾ç½®æœ€ç»ˆå€¼
        
        Args:
            current: å½“å‰æ•°æ®èŠ‚ç‚¹
            final_part: æœ€åä¸€ä¸ªè·¯å¾„éƒ¨åˆ†
            new_value: è¦è®¾ç½®çš„æ–°å€¼
        """
        if '[' in final_part and ']' in final_part:
            # å¤„ç†æ•°ç»„ç´¢å¼•
            key = final_part.split('[')[0]
            index = int(final_part.split('[')[1].split(']')[0])
            
            if key == '':
                # çº¯æ•°ç»„ç´¢å¼•ï¼Œä¾‹å¦‚ "[3]"
                if not isinstance(current, list):
                    logger.error(f"æœŸæœ›æ•°ç»„ä½†å¾—åˆ° {type(current).__name__}")
                    return
                if index >= len(current):
                    logger.error(f"æ•°ç»„ç´¢å¼• {index} è¶…å‡ºèŒƒå›´ï¼ˆé•¿åº¦: {len(current)}ï¼‰")
                    return
                current[index] = new_value
            else:
                # é”®å + æ•°ç»„ç´¢å¼•ï¼Œä¾‹å¦‚ "items[0]"
                if not isinstance(current, dict):
                    logger.error(f"æœŸæœ›å­—å…¸ä½†å¾—åˆ° {type(current).__name__}")
                    return
                if key not in current:
                    logger.error(f"é”® '{key}' ä¸å­˜åœ¨äºå½“å‰æ•°æ®ä¸­")
                    return
                if not isinstance(current[key], list):
                    logger.error(f"'{key}' ä¸æ˜¯æ•°ç»„")
                    return
                if index >= len(current[key]):
                    logger.error(f"æ•°ç»„ '{key}' çš„ç´¢å¼• {index} è¶…å‡ºèŒƒå›´ï¼ˆé•¿åº¦: {len(current[key])}ï¼‰")
                    return
                current[key][index] = new_value
        else:
            # æ™®é€šé”®èµ‹å€¼
            if not isinstance(current, dict):
                logger.error(f"æœŸæœ›å­—å…¸ä½†å¾—åˆ° {type(current).__name__}")
                return
            current[final_part] = new_value
    
    def _delete_value_by_path(self, target_data: Any, path: str):
        """é€šè¿‡è·¯å¾„åˆ é™¤å€¼ - æ ¸å¿ƒæ–¹æ³•"""
        try:
            parts = path.split('.')
            current = target_data
            
            # éå†åˆ°å€’æ•°ç¬¬äºŒå±‚
            for part in parts[:-1]:
                if '[' in part and ']' in part:
                    key = part.split('[')[0]
                    index = int(part.split('[')[1].split(']')[0])
                    current = current[key][index]
                else:
                    current = current[part]
            
            # åˆ é™¤æœ€åä¸€å±‚çš„å€¼
            final_key = parts[-1]
            if '[' in final_key and ']' in final_key:
                key = final_key.split('[')[0]
                index = int(final_key.split('[')[1].split(']')[0])
                if isinstance(current[key], list):
                    current[key].pop(index)
                    logger.info(f"âœ“ æˆåŠŸåˆ é™¤è·¯å¾„ {path} çš„æ•°ç»„å…ƒç´ ")
            else:
                if final_key in current:
                    del current[final_key]
                    logger.info(f"âœ“ æˆåŠŸåˆ é™¤è·¯å¾„ {path} çš„å­—æ®µ")
                    
        except Exception as e:
            logger.error(f"é€šè¿‡è·¯å¾„åˆ é™¤å€¼æ—¶å‡ºé”™ - è·¯å¾„: {path}, é”™è¯¯: {e}")
    
    def _modify_text_with_context(self, target_data: Any, path: str, new_value: Any,
                                leading_context: str = None, target_content: str = None,
                                trailing_context: str = None, condition: Dict = None):
        """
        åŸºäºå‰å¯¼ä¸Šä¸‹æ–‡ç²¾ç¡®å®šä½å¹¶ä¿®æ”¹æ–‡æœ¬å†…å®¹
        
        Args:
            target_data: ç›®æ ‡æ•°æ®ç»“æ„
            path: JSONè·¯å¾„
            new_value: æ–°å€¼
            leading_context: å‰å¯¼ä¸Šä¸‹æ–‡
            target_content: è¦ä¿®æ”¹çš„ç›®æ ‡å†…å®¹
            trailing_context: åå¯¼ä¸Šä¸‹æ–‡
            condition: æŸ¥æ‰¾æ¡ä»¶ï¼ˆä»…åœ¨ç‰¹æ®Šæƒ…å†µä¸‹ä½¿ç”¨ï¼‰
        """
        try:
            logger.info(f"æ‰§è¡Œæ–‡æœ¬ä¸Šä¸‹æ–‡ä¿®æ”¹ - è·¯å¾„: {path}")
            logger.info(f"å‰å¯¼ä¸Šä¸‹æ–‡: '{leading_context}', ç›®æ ‡å†…å®¹: '{target_content}', æ–°å€¼: '{new_value}'")
            
            # å¦‚æœæ²¡æœ‰æä¾›ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå›é€€åˆ°æ™®é€šçš„è®¾ç½®æ–¹æ³•
            if not leading_context and not target_content:
                logger.warning("æœªæä¾›ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå›é€€åˆ°æ™®é€šè®¾ç½®æ–¹æ³•")
                self._set_value_by_path(target_data, path, new_value)
                return
            
            # ä½¿ç”¨è·¯å¾„ç›´æ¥å®šä½åˆ°å­—æ®µï¼Œç„¶ååœ¨å­—æ®µå†…è¿›è¡Œä¸Šä¸‹æ–‡ä¿®æ”¹
            self._modify_text_by_path(target_data, path, new_value, 
                                    leading_context, target_content, 
                                    trailing_context)
                                    
        except Exception as e:
            logger.error(f"åŸºäºä¸Šä¸‹æ–‡ä¿®æ”¹æ–‡æœ¬æ—¶å‡ºé”™: {e}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
    
    def _modify_text_by_path(self, target_data: Any, path: str, new_value: Any,
                           leading_context: str, target_content: str,
                           trailing_context: str):
        """é€šè¿‡è·¯å¾„ç›´æ¥ä¿®æ”¹æ–‡æœ¬å†…å®¹"""
        try:
            # ä½¿ç”¨ç»Ÿä¸€çš„è·¯å¾„è§£ææ–¹æ³•
            tokens = self._parse_path_to_tokens(path)
            logger.info(f"ğŸ”§ _modify_text_by_path è·¯å¾„token: {tokens}")

            if not tokens:
                logger.error("è·¯å¾„è§£æç»“æœä¸ºç©º")
                return

            current = target_data

            # éå†åˆ°å€’æ•°ç¬¬äºŒå±‚
            for token in tokens[:-1]:
                current = self._navigate_by_token(current, token)
                if current is None:
                    return

            # ä¿®æ”¹æœ€åä¸€å±‚çš„æ–‡æœ¬å†…å®¹
            final_token = tokens[-1]

            if final_token.startswith('[') and final_token.endswith(']'):
                # çº¯æ•°ç»„ç´¢å¼•ï¼Œä¾‹å¦‚ "[3]"
                try:
                    index = int(final_token[1:-1])
                except ValueError:
                    logger.error(f"æ— æ•ˆçš„æ•°ç»„ç´¢å¼•: {final_token}")
                    return

                if not isinstance(current, list):
                    logger.error(f"æœŸæœ›æ•°ç»„ä½†å¾—åˆ° {type(current).__name__}")
                    return
                if index >= len(current):
                    logger.error(f"æ•°ç»„ç´¢å¼• {index} è¶…å‡ºèŒƒå›´ï¼ˆé•¿åº¦: {len(current)}ï¼‰")
                    return

                original_text = current[index]
                if isinstance(original_text, str):
                    modified_text = self._replace_text_with_context(
                        original_text, leading_context, target_content,
                        trailing_context, new_value
                    )
                    current[index] = modified_text
                    logger.info(f"âœ“ æˆåŠŸä¿®æ”¹æ–‡æœ¬: {original_text} -> {modified_text}")
                else:
                    logger.error(f"ç´¢å¼• {index} å¤„çš„å€¼ä¸æ˜¯å­—ç¬¦ä¸²: {type(original_text).__name__}")
            else:
                # æ™®é€šé”®è®¿é—®
                if not isinstance(current, dict):
                    logger.error(f"æœŸæœ›å­—å…¸ä½†å¾—åˆ° {type(current).__name__}")
                    return
                if final_token not in current:
                    logger.error(f"é”® '{final_token}' ä¸å­˜åœ¨äºå½“å‰æ•°æ®ä¸­")
                    return

                if isinstance(current[final_token], str):
                    original_text = current[final_token]
                    modified_text = self._replace_text_with_context(
                        original_text, leading_context, target_content,
                        trailing_context, new_value
                    )
                    current[final_token] = modified_text
                    logger.info(f"âœ“ æˆåŠŸä¿®æ”¹æ–‡æœ¬: {original_text} -> {modified_text}")
                else:
                    logger.error(f"é”® '{final_token}' çš„å€¼ä¸æ˜¯å­—ç¬¦ä¸²: {type(current[final_token]).__name__}")
                    
        except Exception as e:
            logger.error(f"é€šè¿‡è·¯å¾„ä¿®æ”¹æ–‡æœ¬æ—¶å‡ºé”™: {e}")
    
    def _modify_nested_text(self, data: Any, path_parts: List[str], new_value: Any,
                          leading_context: str, target_content: str, 
                          trailing_context: str) -> bool:
        """é€’å½’ä¿®æ”¹åµŒå¥—ç»“æ„ä¸­çš„æ–‡æœ¬"""
        try:
            if not path_parts:
                return False
                
            current_part = path_parts[0]
            remaining_parts = path_parts[1:]
            
            if isinstance(data, dict):
                if '[' in current_part and ']' in current_part:
                    # å¤„ç†æ•°ç»„ç´¢å¼•
                    key = current_part.split('[')[0]
                    index = int(current_part.split('[')[1].split(']')[0])
                    if key in data and isinstance(data[key], list) and index < len(data[key]):
                        if not remaining_parts:
                            # åˆ°è¾¾ç›®æ ‡ä½ç½®
                            original_text = data[key][index]
                            if isinstance(original_text, str):
                                modified_text = self._replace_text_with_context(
                                    original_text, leading_context, target_content, 
                                    trailing_context, new_value
                                )
                                data[key][index] = modified_text
                                return True
                        else:
                            # ç»§ç»­é€’å½’
                            return self._modify_nested_text(data[key][index], remaining_parts, 
                                                          new_value, leading_context, 
                                                          target_content, trailing_context)
                else:
                    if current_part in data:
                        if not remaining_parts:
                            # åˆ°è¾¾ç›®æ ‡ä½ç½®
                            if isinstance(data[current_part], str):
                                original_text = data[current_part]
                                modified_text = self._replace_text_with_context(
                                    original_text, leading_context, target_content, 
                                    trailing_context, new_value
                                )
                                data[current_part] = modified_text
                                return True
                        else:
                            # ç»§ç»­é€’å½’
                            return self._modify_nested_text(data[current_part], remaining_parts, 
                                                          new_value, leading_context, 
                                                          target_content, trailing_context)
            elif isinstance(data, list):
                # å¦‚æœå½“å‰æ˜¯åˆ—è¡¨ï¼Œå°è¯•åœ¨æ‰€æœ‰é¡¹ä¸­æŸ¥æ‰¾
                for item in data:
                    if self._modify_nested_text(item, path_parts, new_value, 
                                              leading_context, target_content, 
                                              trailing_context):
                        return True
                        
        except Exception as e:
            logger.error(f"é€’å½’ä¿®æ”¹åµŒå¥—æ–‡æœ¬æ—¶å‡ºé”™: {e}")
            
        return False
    
    def _replace_text_with_context(self, original_text: str, leading_context: str,
                                 target_content: str, trailing_context: str, 
                                 new_value: str) -> str:
        """
        åŸºäºå‰å¯¼ä¸Šä¸‹æ–‡æ›¿æ¢æ–‡æœ¬å†…å®¹ï¼Œéµå¾ªæœ€å°ä¸Šä¸‹æ–‡å®šä½åŸåˆ™
        
        Args:
            original_text: åŸå§‹æ–‡æœ¬
            leading_context: å‰å¯¼ä¸Šä¸‹æ–‡
            target_content: è¦æ›¿æ¢çš„ç›®æ ‡å†…å®¹
            trailing_context: åå¯¼ä¸Šä¸‹æ–‡
            new_value: æ–°å€¼
            
        Returns:
            æ›¿æ¢åçš„æ–‡æœ¬
        """
        try:
            if not original_text or not isinstance(original_text, str):
                return original_text
            
            if not target_content:
                logger.warning("æœªæä¾›ç›®æ ‡å†…å®¹ï¼Œæ— æ³•è¿›è¡Œæ›¿æ¢")
                return original_text
            
            # 1. é¦–å…ˆå°è¯•æœ€å°ä¸Šä¸‹æ–‡å®šä½ï¼ˆåªç”¨leading_context + target_contentï¼‰
            if leading_context:
                minimal_pattern = re.escape(leading_context) + re.escape(target_content)
                if re.search(minimal_pattern, original_text):
                    # æ£€æŸ¥æ˜¯å¦å”¯ä¸€åŒ¹é…
                    matches = list(re.finditer(minimal_pattern, original_text))
                    if len(matches) == 1:
                        # å”¯ä¸€åŒ¹é…ï¼Œä½¿ç”¨æœ€å°ä¸Šä¸‹æ–‡
                        replacement = leading_context + new_value
                        modified_text = re.sub(minimal_pattern, replacement, original_text, count=1)
                        logger.info(f"âœ“ ä½¿ç”¨æœ€å°ä¸Šä¸‹æ–‡å®šä½æˆåŠŸ: '{leading_context}{target_content}' -> '{leading_context}{new_value}'")
                        return modified_text
                    else:
                        logger.info(f"æœ€å°ä¸Šä¸‹æ–‡åŒ¹é…åˆ°{len(matches)}ä¸ªç»“æœï¼Œå°è¯•ä½¿ç”¨å®Œæ•´ä¸Šä¸‹æ–‡")
                
                # 2. å¦‚æœæœ€å°ä¸Šä¸‹æ–‡ä¸å”¯ä¸€ï¼Œä½¿ç”¨å®Œæ•´ä¸Šä¸‹æ–‡
                if trailing_context:
                    full_pattern = re.escape(leading_context) + re.escape(target_content) + re.escape(trailing_context)
                    if re.search(full_pattern, original_text):
                        replacement = leading_context + new_value + trailing_context
                        modified_text = re.sub(full_pattern, replacement, original_text, count=1)
                        logger.info(f"âœ“ ä½¿ç”¨å®Œæ•´ä¸Šä¸‹æ–‡å®šä½æˆåŠŸ")
                        return modified_text
                    else:
                        logger.warning(f"å®Œæ•´ä¸Šä¸‹æ–‡æ¨¡å¼æœªåŒ¹é…: '{leading_context}{target_content}{trailing_context}'")
                
                # 3. å›é€€åˆ°ç®€å•çš„ç›®æ ‡å†…å®¹æ›¿æ¢
                if target_content in original_text:
                    # æ£€æŸ¥ç›®æ ‡å†…å®¹æ˜¯å¦å”¯ä¸€
                    occurrences = original_text.count(target_content)
                    if occurrences == 1:
                        modified_text = original_text.replace(target_content, new_value, 1)
                        logger.info(f"âœ“ ä½¿ç”¨ç›®æ ‡å†…å®¹ç›´æ¥æ›¿æ¢æˆåŠŸï¼ˆå”¯ä¸€åŒ¹é…ï¼‰")
                        return modified_text
                    else:
                        logger.warning(f"ç›®æ ‡å†…å®¹ '{target_content}' åœ¨æ–‡æœ¬ä¸­å‡ºç°{occurrences}æ¬¡ï¼Œæ— æ³•å”¯ä¸€å®šä½")
                        return original_text
            
            # 4. å¦‚æœæ²¡æœ‰å‰å¯¼ä¸Šä¸‹æ–‡ï¼Œåªèƒ½ç›´æ¥æ›¿æ¢ç›®æ ‡å†…å®¹
            elif target_content in original_text:
                occurrences = original_text.count(target_content)
                if occurrences == 1:
                    modified_text = original_text.replace(target_content, new_value, 1)
                    logger.info(f"âœ“ ç›´æ¥æ›¿æ¢ç›®æ ‡å†…å®¹æˆåŠŸï¼ˆå”¯ä¸€åŒ¹é…ï¼‰")
                    return modified_text
                else:
                    logger.warning(f"ç›®æ ‡å†…å®¹ '{target_content}' åœ¨æ–‡æœ¬ä¸­å‡ºç°{occurrences}æ¬¡ï¼Œå»ºè®®æä¾›å‰å¯¼ä¸Šä¸‹æ–‡")
                    return original_text
                    
            logger.warning(f"æœªæ‰¾åˆ°åŒ¹é…çš„æ–‡æœ¬è¿›è¡Œæ›¿æ¢")
            return original_text
            
        except Exception as e:
            logger.error(f"æ›¿æ¢æ–‡æœ¬æ—¶å‡ºé”™: {e}")
            return original_text
    
    def _check_and_update_related_fields(self, target_data: Any, path: str, new_value: Any):
        """
        æ£€æŸ¥å¹¶æ›´æ–°ç›¸å…³è”çš„å­—æ®µï¼Œå¦‚æŒ‡æ ‡å€¼ä¿®æ”¹æ—¶æ›´æ–°å¼‚å¸¸çŠ¶æ€
        
        Args:
            target_data: ç›®æ ‡æ•°æ®ç»“æ„
            path: ä¿®æ”¹çš„å­—æ®µè·¯å¾„
            new_value: æ–°å€¼
        """
        try:
            # æ£€æŸ¥æ˜¯å¦æ˜¯æŒ‡æ ‡æ•°æ®çš„ä¿®æ”¹
            if "indicator_series" in path and "value" in path:
                self._update_indicator_abnormal_status(target_data, path, new_value)
            elif "series" in path and isinstance(new_value, (int, float)):
                self._update_indicator_abnormal_status(target_data, path, new_value)
            
            # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ å…¶ä»–å…³è”æ›´æ–°é€»è¾‘
            
        except Exception as e:
            logger.error(f"æ›´æ–°å…³è”å­—æ®µæ—¶å‡ºé”™: {e}")
    
    def _update_indicator_abnormal_status(self, target_data: Any, path: str, new_value: Any):
        """
        æ›´æ–°æŒ‡æ ‡çš„å¼‚å¸¸çŠ¶æ€æ ‡è¯†
        
        Args:
            target_data: ç›®æ ‡æ•°æ®ç»“æ„
            path: æŒ‡æ ‡å€¼çš„è·¯å¾„
            new_value: æ–°çš„æŒ‡æ ‡å€¼
        """
        try:
            if not isinstance(new_value, (int, float)):
                return
            
            # è§£æè·¯å¾„è·å–æŒ‡æ ‡ä¿¡æ¯
            path_parts = path.split('.')
            
            # æŸ¥æ‰¾æŒ‡æ ‡åºåˆ—æ•°æ®
            indicators = target_data.get("indicator_series", [])
            if not indicators:
                return
            
            # æ ¹æ®è·¯å¾„å®šä½åˆ°å…·ä½“çš„æŒ‡æ ‡å’Œæ—¶é—´ç‚¹
            for indicator in indicators:
                if not isinstance(indicator, dict):
                    continue
                    
                series = indicator.get("series", [])
                normal_min = indicator.get("normal_min")
                normal_max = indicator.get("normal_max")
                
                # å¦‚æœæœ‰æ­£å¸¸èŒƒå›´ï¼Œæ›´æ–°å¼‚å¸¸çŠ¶æ€
                if normal_min is not None and normal_max is not None:
                    for series_item in series:
                        if isinstance(series_item, dict) and series_item.get("value") == new_value:
                            # åˆ¤æ–­æ˜¯å¦å¼‚å¸¸
                            is_abnormal = not (normal_min <= new_value <= normal_max)
                            series_item["is_abnormal"] = is_abnormal
                            
                            # æ›´æ–°å¼‚å¸¸çŠ¶æ€æè¿°
                            if is_abnormal:
                                if new_value > normal_max:
                                    series_item["abnormal_type"] = "åé«˜"
                                elif new_value < normal_min:
                                    series_item["abnormal_type"] = "åä½"
                            else:
                                series_item.pop("abnormal_type", None)
                            
                            logger.info(f"âœ“ æ›´æ–°æŒ‡æ ‡å¼‚å¸¸çŠ¶æ€: {indicator.get('name', '')} = {new_value}, å¼‚å¸¸: {is_abnormal}")
                            
        except Exception as e:
            logger.error(f"æ›´æ–°æŒ‡æ ‡å¼‚å¸¸çŠ¶æ€æ—¶å‡ºé”™: {e}")
    
    def _find_and_replace_text_recursive(self, data: Any, path: str, search_text: str, new_value: str) -> bool:
        """
        é€’å½’æŸ¥æ‰¾å¹¶æ›¿æ¢æ•°æ®ç»“æ„ä¸­åŒ…å«ç‰¹å®šæ–‡æœ¬çš„å†…å®¹
        
        Args:
            data: è¦æœç´¢çš„æ•°æ®ç»“æ„
            path: ç›®æ ‡è·¯å¾„ï¼ˆç”¨äºæ—¥å¿—è®°å½•ï¼‰
            search_text: è¦æŸ¥æ‰¾çš„æ–‡æœ¬
            new_value: æ›¿æ¢çš„æ–°å€¼
            
        Returns:
            æ˜¯å¦æˆåŠŸæ‰¾åˆ°å¹¶æ›¿æ¢äº†æ–‡æœ¬
        """
        try:
            modified = False
            
            if isinstance(data, dict):
                for key, value in data.items():
                    if isinstance(value, str) and search_text in value:
                        # æ‰¾åˆ°åŒ…å«ç›®æ ‡æ–‡æœ¬çš„å­—ç¬¦ä¸²
                        old_value = value
                        if "æ›¿æ¢ä¸º" in new_value:
                            # å¤„ç†"Aæ›¿æ¢ä¸ºB"æ ¼å¼çš„æŒ‡ä»¤
                            parts = new_value.split("æ›¿æ¢ä¸º")
                            if len(parts) == 2:
                                replacement_text = parts[1].strip()
                                data[key] = value.replace(search_text, replacement_text)
                                logger.info(f"âœ“ æ›¿æ¢æ–‡æœ¬ '{key}': {old_value} -> {data[key]}")
                                modified = True
                        else:
                            # ç›´æ¥æ›¿æ¢
                            data[key] = value.replace(search_text, new_value)
                            logger.info(f"âœ“ æ›¿æ¢æ–‡æœ¬ '{key}': {old_value} -> {data[key]}")
                            modified = True
                    elif isinstance(value, (dict, list)):
                        # é€’å½’æœç´¢åµŒå¥—ç»“æ„
                        if self._find_and_replace_text_recursive(value, f"{path}.{key}", search_text, new_value):
                            modified = True
                            
            elif isinstance(data, list):
                for i, item in enumerate(data):
                    if isinstance(item, str) and search_text in item:
                        # æ‰¾åˆ°åŒ…å«ç›®æ ‡æ–‡æœ¬çš„å­—ç¬¦ä¸²
                        old_value = item
                        if "æ›¿æ¢ä¸º" in new_value:
                            # å¤„ç†"Aæ›¿æ¢ä¸ºB"æ ¼å¼çš„æŒ‡ä»¤
                            parts = new_value.split("æ›¿æ¢ä¸º")
                            if len(parts) == 2:
                                replacement_text = parts[1].strip()
                                data[i] = item.replace(search_text, replacement_text)
                                logger.info(f"âœ“ æ›¿æ¢æ•°ç»„æ–‡æœ¬ [{i}]: {old_value} -> {data[i]}")
                                modified = True
                        else:
                            # ç›´æ¥æ›¿æ¢
                            data[i] = item.replace(search_text, new_value)
                            logger.info(f"âœ“ æ›¿æ¢æ•°ç»„æ–‡æœ¬ [{i}]: {old_value} -> {data[i]}")
                            modified = True
                    elif isinstance(item, (dict, list)):
                        # é€’å½’æœç´¢åµŒå¥—ç»“æ„
                        if self._find_and_replace_text_recursive(item, f"{path}[{i}]", search_text, new_value):
                            modified = True
                            
            return modified
            
        except Exception as e:
            logger.error(f"é€’å½’æ–‡æœ¬æŸ¥æ‰¾æ›¿æ¢æ—¶å‡ºé”™: {e}")
            return False
    
    def _save_patient_data_to_output(self, session_id, patient_content, full_structure_data, patient_journey=None, mdt_simple_report=None):
        """å°†æ‚£è€…æ•°æ®ä¿å­˜åˆ°è¾“å‡ºç›®å½•"""
        try:
            if not session_id:
                logger.warning("No session_id provided, skipping patient data save")
                return None
            
            # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„ï¼ˆä¸intent_determine_crewç›¸åŒçš„ç›®å½•ç»“æ„ï¼‰
            output_dir = Path("output/files_extract") / session_id
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # ç¡®ä¿æ•°æ®ä¸­çš„Unicodeç¼–ç è¢«æ­£ç¡®è§£ç 
            def decode_unicode_recursive(obj):
                """é€’å½’è§£ç å¯¹è±¡ä¸­çš„Unicodeè½¬ä¹‰åºåˆ—"""
                if isinstance(obj, dict):
                    return {key: decode_unicode_recursive(value) for key, value in obj.items()}
                elif isinstance(obj, list):
                    return [decode_unicode_recursive(item) for item in obj]
                elif isinstance(obj, str):
                    try:
                        # å¤„ç†Unicodeè½¬ä¹‰åºåˆ—
                        if '\\u' in obj:
                            return obj.encode().decode('unicode_escape')
                        return obj
                    except Exception:
                        return obj
                else:
                    return obj
            
            # å‡†å¤‡è¦ä¿å­˜çš„æ•°æ®
            patient_data = {
                "session_id": session_id,
                "timestamp": time.time(),
                "processing_date": datetime.now().isoformat(),
                "patient_content": decode_unicode_recursive(patient_content) if isinstance(patient_content, str) else patient_content,
                "full_structure_data": decode_unicode_recursive(full_structure_data),
                "patient_journey": decode_unicode_recursive(patient_journey) if patient_journey is not None else None,
                "mdt_simple_report": decode_unicode_recursive(mdt_simple_report) if mdt_simple_report is not None else None
            }
            
            # ä¿å­˜åˆ°JSONæ–‡ä»¶
            output_file = output_dir / "patient_data.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(patient_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"æ‚£è€…æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
            
            return str(output_file)
            
        except Exception as e:
            logger.error(f"ä¿å­˜æ‚£è€…æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            return None

    @agent
    def modification_summary_analyzer(self) -> Agent:
        """ä¿®æ”¹æ‘˜è¦åˆ†æä¸“å®¶ï¼šè¯†åˆ«æ‰€æœ‰éœ€è¦ä¿®æ”¹çš„ä½ç½®"""
        return Agent(
            config=self.agents_config['modification_summary_analyzer'],
            llm=general_llm,
            verbose=True
        )

    @agent
    def modification_details_generator(self) -> Agent:
        """ä¿®æ”¹æ˜ç»†ç”Ÿæˆä¸“å®¶ï¼šç”Ÿæˆè¯¦ç»†çš„ä¿®æ”¹æŒ‡ä»¤"""
        return Agent(
            config=self.agents_config['modification_details_generator'],
            llm=general_llm,
            verbose=True
        )

    @agent
    def update_analyzer(self) -> Agent:
        """æ›´æ–°åˆ†æä¸“å®¶ï¼šåˆ†æç”¨æˆ·çš„æ›´æ–°éœ€æ±‚å¹¶è¿”å›ä¿®æ”¹æŒ‡ä»¤"""
        return Agent(
            config=self.agents_config['update_analyzer'],
            llm=general_llm,
            verbose=True
        )

    @task
    def analyze_modification_summary_task(self) -> Task:
        """åˆ†æä¿®æ”¹æ‘˜è¦ä»»åŠ¡"""
        return Task(
            config=self.tasks_config['analyze_modification_summary_task']
        )

    @task
    def generate_modification_details_task(self) -> Task:
        """ç”Ÿæˆä¿®æ”¹æ˜ç»†ä»»åŠ¡"""
        return Task(
            config=self.tasks_config['generate_modification_details_task']
        )

    @task
    def analyze_and_modify_task(self) -> Task:
        """åˆ†æå¹¶ç”Ÿæˆä¿®æ”¹æŒ‡ä»¤ä»»åŠ¡"""
        return Task(
            config=self.tasks_config['analyze_and_modify_task']
        )

    @crew
    def crew(self) -> Crew:
        """åˆ›å»ºæ‚£è€…ä¿¡æ¯æ›´æ–°crew"""
        return Crew(
            agents=self.agents,
            tasks=self.tasks,
            process=Process.sequential,
            verbose=True
        )

    async def update_patient_info(self, user_request: str, current_patient_data: Dict,
                                  session_id: str = None) -> Dict:
        """
        æ›´æ–°æ‚£è€…ä¿¡æ¯çš„ä¸»è¦æ–¹æ³•

        Args:
            user_request: ç”¨æˆ·çš„æ›´æ–°è¯·æ±‚
            current_patient_data: å½“å‰çš„æ‚£è€…æ•°æ®
            session_id: ä¼šè¯ID

        Returns:
            æ›´æ–°åçš„æ‚£è€…æ•°æ®ï¼Œæ ¼å¼ä¸patient_data_crewä¿æŒä¸€è‡´
        """
        try:
            logger.info("Starting patient info update process")
            current_date = datetime.now().strftime("%Y-%m-%d")

            # ğŸ†• åˆå§‹åŒ–Tokenç®¡ç†å’Œæ•°æ®å‹ç¼©æ¨¡å—ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰
            # ä¼˜å…ˆä½¿ç”¨ä¸»å¼€å…³ ENABLE_NEW_FEATURESï¼Œå¦‚æœæœªè®¾ç½®åˆ™ä½¿ç”¨ ENABLE_DATA_COMPRESSION
            enable_new_features = os.getenv('ENABLE_NEW_FEATURES', '').lower()

            if enable_new_features in ('true', '1', 'yes'):
                # ä¸»å¼€å…³å¯ç”¨ - å¯ç”¨æ‰€æœ‰æ–°åŠŸèƒ½
                enable_compression = True
                logger.info("âœ… ä¸»å¼€å…³å·²å¯ç”¨ (ENABLE_NEW_FEATURES=true)ï¼Œå°†ä½¿ç”¨æ‰€æœ‰æ–°åŠŸèƒ½")
            elif enable_new_features in ('false', '0', 'no'):
                # ä¸»å¼€å…³ç¦ç”¨ - ä½¿ç”¨åŸæœ‰é€»è¾‘
                enable_compression = False
                logger.info("â„¹ï¸ ä¸»å¼€å…³å·²ç¦ç”¨ (ENABLE_NEW_FEATURES=false)ï¼Œä½¿ç”¨åŸæœ‰é€»è¾‘")
            else:
                # æœªè®¾ç½®ä¸»å¼€å…³ - ä½¿ç”¨ç»†ç²’åº¦æ§åˆ¶
                enable_compression = os.getenv('ENABLE_DATA_COMPRESSION', 'false').lower() in ('true', '1', 'yes')
                if enable_compression:
                    logger.info("âœ… æ•°æ®å‹ç¼©åŠŸèƒ½å·²å¯ç”¨ (ENABLE_DATA_COMPRESSION=true)")
                else:
                    logger.info("â„¹ï¸ æ•°æ®å‹ç¼©åŠŸèƒ½æœªå¯ç”¨ï¼ˆä½¿ç”¨åŸæœ‰é€»è¾‘ï¼‰ï¼Œå¯é€šè¿‡ ENABLE_NEW_FEATURES=true æˆ– ENABLE_DATA_COMPRESSION=true å¯ç”¨")

            if not enable_compression:
                # ç›´æ¥ä½¿ç”¨åŸå§‹æ•°æ®ï¼Œä¸å‹ç¼©
                compressed_patient_data = current_patient_data
            else:
                logger.info("âœ… æ•°æ®å‹ç¼©åŠŸèƒ½å·²å¯ç”¨")
                token_manager = TokenManager(logger=logger)
                data_compressor = PatientDataCompressor(logger=logger, token_manager=token_manager)

                # ğŸ†• å‹ç¼©æ‚£è€…æ•°æ®ï¼ˆåœ¨ä¼ é€’ç»™LLMå‰ï¼‰
                model_name = 'deepseek-chat'  # ä½¿ç”¨general_llmçš„æ¨¡å‹

                # æ£€æŸ¥æ•°æ®å¤§å°
                check_result = token_manager.check_input_limit(current_patient_data, model_name)
                logger.info(f"ğŸ“Š æ‚£è€…æ•°æ®ç»Ÿè®¡:")
                logger.info(f"  â”œâ”€ ä¼°ç®—æ€»tokens: {check_result['total_tokens']}")
                logger.info(f"  â”œâ”€ æ¨¡å‹é™åˆ¶: {check_result['limit']} tokens")
                logger.info(f"  â”œâ”€ å®‰å…¨é™åˆ¶: {check_result['safe_limit']} tokens")
                logger.info(f"  â”œâ”€ ä½¿ç”¨ç‡: {check_result['usage_ratio']:.1%}")
                logger.info(f"  â””â”€ éœ€è¦å‹ç¼©: {'æ˜¯ âš ï¸' if check_result['compression_needed'] else 'å¦ âœ…'}")

                # å¦‚æœéœ€è¦å‹ç¼©ï¼Œè¿›è¡Œæ•°æ®å‹ç¼©
                compressed_patient_data = current_patient_data
                if check_result['compression_needed']:
                    try:
                        logger.warning("=" * 100)
                        logger.warning(f"âš ï¸ æ‚£è€…æ•°æ®è¶…è¿‡å®‰å…¨é™åˆ¶ï¼Œå¯åŠ¨è‡ªåŠ¨å‹ç¼©æµç¨‹")
                        logger.warning(f"âš ï¸ å½“å‰: {check_result['total_tokens']} tokens > å®‰å…¨é™åˆ¶: {check_result['safe_limit']} tokens")
                        logger.warning("=" * 100)

                        # è®¡ç®—ç›®æ ‡tokenæ•°
                        target_tokens = check_result['safe_limit']

                        # å‹ç¼©å„ä¸ªæ¨¡å—çš„æ•°æ®
                        compressed_patient_data = {}

                        # 1. å‹ç¼©patient_timelineï¼ˆåˆ†é…40%çš„ç›®æ ‡tokenï¼‰
                        if "patient_timeline" in current_patient_data:
                            logger.info(f"ğŸ“¦ å¼€å§‹å‹ç¼©patient_timelineæ•°æ® (ç›®æ ‡: {int(target_tokens * 0.4)} tokens)...")
                            compressed_patient_data["patient_timeline"] = data_compressor.compress_timeline(
                                current_patient_data["patient_timeline"],
                                max_tokens=int(target_tokens * 0.4),
                                model_name=model_name
                            )
                            logger.info(f"  âœ… patient_timelineå‹ç¼©å®Œæˆ")

                        # 2. å‹ç¼©patient_journeyï¼ˆåˆ†é…30%çš„ç›®æ ‡tokenï¼‰
                        if "patient_journey" in current_patient_data:
                            logger.info(f"ğŸ“¦ å¼€å§‹å‹ç¼©patient_journeyæ•°æ® (ç›®æ ‡: {int(target_tokens * 0.3)} tokens)...")
                            compressed_patient_data["patient_journey"] = data_compressor.compress_data(
                                current_patient_data["patient_journey"],
                                max_tokens=int(target_tokens * 0.3),
                                model_name=model_name
                            )
                            logger.info(f"  âœ… patient_journeyå‹ç¼©å®Œæˆ")

                        # 3. å‹ç¼©mdt_simple_reportï¼ˆåˆ†é…30%çš„ç›®æ ‡tokenï¼‰
                        if "mdt_simple_report" in current_patient_data:
                            logger.info(f"ğŸ“¦ å¼€å§‹å‹ç¼©mdt_simple_reportæ•°æ® (ç›®æ ‡: {int(target_tokens * 0.3)} tokens)...")
                            compressed_patient_data["mdt_simple_report"] = data_compressor.compress_data(
                                current_patient_data["mdt_simple_report"],
                                max_tokens=int(target_tokens * 0.3),
                                model_name=model_name
                            )
                            logger.info(f"  âœ… mdt_simple_reportå‹ç¼©å®Œæˆ")

                        # ä¿ç•™å…¶ä»–å­—æ®µ
                        for key in current_patient_data:
                            if key not in ["patient_timeline", "patient_journey", "mdt_simple_report"]:
                                compressed_patient_data[key] = current_patient_data[key]

                        # é‡æ–°æ£€æŸ¥å‹ç¼©åçš„tokenæ•°
                        compressed_check = token_manager.check_input_limit(compressed_patient_data, model_name)
                        logger.info("=" * 100)
                        logger.info(f"âœ… æ•°æ®å‹ç¼©å®Œæˆï¼")
                        logger.info(f"ğŸ“Š å‹ç¼©æ•ˆæœ:")
                        logger.info(f"  â”œâ”€ åŸå§‹tokens: {check_result['total_tokens']}")
                        logger.info(f"  â”œâ”€ å‹ç¼©åtokens: {compressed_check['total_tokens']}")
                        logger.info(f"  â”œâ”€ å‹ç¼©æ¯”ä¾‹: {compressed_check['total_tokens']/check_result['total_tokens']:.1%}")
                        logger.info(f"  â”œâ”€ æ–°ä½¿ç”¨ç‡: {compressed_check['usage_ratio']:.1%}")
                        logger.info(f"  â””â”€ åœ¨é™åˆ¶å†…: {'æ˜¯ âœ…' if compressed_check['within_limit'] else 'å¦ âŒ'}")
                        logger.info("=" * 100)
                    except Exception as e:
                        logger.error(f"âŒ æ•°æ®å‹ç¼©å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ•°æ®: {e}")
                        compressed_patient_data = current_patient_data
                else:
                    logger.info("=" * 100)
                    logger.info(f"âœ… æ•°æ®é‡åœ¨å®‰å…¨èŒƒå›´å†…ï¼Œæ— éœ€å‹ç¼©")
                    logger.info("=" * 100)

            # ========== é˜¶æ®µ1: ç”Ÿæˆä¿®æ”¹æ‘˜è¦ ==========
            logger.info("=" * 80)
            logger.info("ã€é˜¶æ®µ1ã€‘å¼€å§‹ç”Ÿæˆä¿®æ”¹æ‘˜è¦")
            logger.info("=" * 80)

            summary_inputs = {
                "user_request": user_request,
                "current_patient_data": compressed_patient_data
            }

            # åˆ›å»ºæ–°çš„Taskå®ä¾‹
            summary_task = Task(
                config=self.tasks_config['analyze_modification_summary_task']
            )
            summary_task.interpolate_inputs_and_add_conversation_history(summary_inputs)
            summary_result = self.modification_summary_analyzer().execute_task(summary_task)

            # è§£æä¿®æ”¹æ‘˜è¦
            modification_summary = JsonUtils.safe_parse_json(summary_result, debug_prefix="Modification summary")
            if not modification_summary or not isinstance(modification_summary, list):
                logger.error("ä¿®æ”¹æ‘˜è¦è§£æå¤±è´¥æˆ–æ ¼å¼ä¸æ­£ç¡®")
                return {
                    "error": f"ä¿®æ”¹æ‘˜è¦è§£æå¤±è´¥ã€‚åŸå§‹ç»“æœ: {str(summary_result)[:200]}..."
                }

            logger.info(f"æˆåŠŸç”Ÿæˆä¿®æ”¹æ‘˜è¦ï¼ŒåŒ…å« {len(modification_summary)} ä¸ªä¿®æ”¹æ“ä½œ")
            for item in modification_summary:
                logger.info(f"  - {item.get('id')}: {item.get('target_location')} - {item.get('brief_description')}")

            # ========== é˜¶æ®µ2: åˆ†æ‰¹ç”Ÿæˆä¿®æ”¹æ˜ç»† ==========
            logger.info("=" * 80)
            logger.info("ã€é˜¶æ®µ2ã€‘å¼€å§‹åˆ†æ‰¹ç”Ÿæˆä¿®æ”¹æ˜ç»†")
            logger.info("=" * 80)

            batch_size = 2  # æ¯æ‰¹å¤„ç†2ä¸ªä¿®æ”¹æ“ä½œ
            all_modifications = []

            # åˆ†æ‰¹å¤„ç†
            for batch_start in range(0, len(modification_summary), batch_size):
                batch_items = modification_summary[batch_start:batch_start + batch_size]
                batch_num = batch_start // batch_size + 1
                total_batches = (len(modification_summary) + batch_size - 1) // batch_size
                batch_ids = [item.get('id') for item in batch_items]

                logger.info(f"å¤„ç†ç¬¬ {batch_num}/{total_batches} æ‰¹ï¼ŒåŒ…å« {len(batch_items)} ä¸ªä¿®æ”¹æ“ä½œ")
                logger.info(f"  ä¿®æ”¹ID: {batch_ids}")

                try:
                    # åˆ›å»ºæ–°çš„Taskå®ä¾‹
                    details_task = Task(
                        config=self.tasks_config['generate_modification_details_task']
                    )

                    details_inputs = {
                        "current_patient_data": compressed_patient_data,
                        "modification_summary": modification_summary,
                        "target_modification_ids": batch_ids
                    }

                    details_task.interpolate_inputs_and_add_conversation_history(details_inputs)
                    details_result = self.modification_details_generator().execute_task(details_task)

                    # è§£æä¿®æ”¹æ˜ç»†
                    batch_modifications = JsonUtils.safe_parse_json(details_result, debug_prefix=f"Modification details batch {batch_num}")
                    if batch_modifications and isinstance(batch_modifications, list):
                        all_modifications.extend(batch_modifications)
                        logger.info(f"  æˆåŠŸç”Ÿæˆ {len(batch_modifications)} ä¸ªä¿®æ”¹æŒ‡ä»¤")
                    else:
                        logger.warning(f"  æ‰¹æ¬¡ {batch_num} çš„ä¿®æ”¹æ˜ç»†è§£æå¤±è´¥")
                except Exception as e:
                    logger.error(f"å¤„ç†æ‰¹æ¬¡ {batch_num} æ—¶å‡ºé”™: {e}")
                    import traceback
                    logger.error(traceback.format_exc())

            logger.info(f"æ‰€æœ‰ä¿®æ”¹æ˜ç»†ç”Ÿæˆå®Œæˆï¼Œå…± {len(all_modifications)} ä¸ªä¿®æ”¹æŒ‡ä»¤")

            # ========== é˜¶æ®µ3: æ‰§è¡Œä¿®æ”¹æ“ä½œ ==========
            logger.info("=" * 80)
            logger.info("ã€é˜¶æ®µ3ã€‘å¼€å§‹æ‰§è¡Œä¿®æ”¹æ“ä½œ")
            logger.info("=" * 80)

            if not all_modifications:
                logger.warning("æ²¡æœ‰ç”Ÿæˆä»»ä½•ä¿®æ”¹æŒ‡ä»¤")
                return {
                    "error": "æ²¡æœ‰ç”Ÿæˆä»»ä½•ä¿®æ”¹æŒ‡ä»¤"
                }

            # ä¸ºä¿®æ”¹æŒ‡ä»¤æ·»åŠ sequenceå­—æ®µï¼ˆå¦‚æœæ²¡æœ‰çš„è¯ï¼‰
            for idx, mod in enumerate(all_modifications):
                if 'sequence' not in mod:
                    mod['sequence'] = idx + 1

            # ä½¿ç”¨ä»£ç æ‰§è¡Œä¿®æ”¹æŒ‡ä»¤
            logger.info(f"å¼€å§‹æ‰§è¡Œä¿®æ”¹æ“ä½œï¼Œä¿®æ”¹æŒ‡ä»¤æ•°é‡: {len(all_modifications)}")
            updated_data = self._execute_modifications(current_patient_data, all_modifications)
            logger.info(f"ä¿®æ”¹æ“ä½œå®Œæˆ")

            # å‡†å¤‡è¿”å›çš„ç»“æœï¼Œæ ¼å¼ä¸patient_data_crewä¿æŒä¸€è‡´
            # ç›´æ¥ä½¿ç”¨åŸæœ‰çš„patient_contentï¼Œä¸åšä¿®æ”¹
            original_patient_content = current_patient_data.get("patient_content", "")

            result_data = {
                "patient_content": original_patient_content,
                "full_structure_data": updated_data.get("patient_timeline", {}),
                "patient_journey": updated_data.get("patient_journey", {}),
                "mdt_simple_report": updated_data.get("mdt_simple_report", {})
            }

            # ä¿å­˜æ‚£è€…æ•°æ®åˆ°è¾“å‡ºç›®å½•ï¼ˆä¸intent_determine_crewç›¸åŒçš„sessionç›®å½•ï¼‰
            if session_id:
                output_file_path = self._save_patient_data_to_output(
                    session_id,
                    result_data["patient_content"],
                    result_data["full_structure_data"],
                    result_data.get("patient_journey"),
                    result_data.get("mdt_simple_report")
                )
                if output_file_path:
                    logger.info(f"æ‚£è€…æ•°æ®å·²ä¿å­˜åˆ°è¾“å‡ºç›®å½•: {output_file_path}")
                else:
                    logger.warning("ä¿å­˜æ‚£è€…æ•°æ®åˆ°è¾“å‡ºç›®å½•å¤±è´¥")
            else:
                logger.warning("No agent_session_id provided, skipping patient data save")

            return result_data

        except Exception as e:
            logger.error(f"Error updating patient info: {e}")
            logger.error(f"é”™è¯¯ç±»å‹: {type(e)}")
            import traceback
            logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return {"error": str(e)}

    async def task_async(self, central_command: str, user_requirement: str, 
                        current_patient_data: Dict,
                        writer=None, show_status_realtime: bool = False,
                        agent_session_id: str = None) -> Dict:
        """
        å¼‚æ­¥ä»»åŠ¡æ¥å£ï¼Œä¸å…¶ä»–crewä¿æŒä¸€è‡´
        """
        try:
            if show_status_realtime and writer:
                # å‘é€å¼€å§‹çŠ¶æ€
                writer({
                    "type": "status",
                    "agent_name": "æ‚£è€…ä¿¡æ¯ä¿®æ”¹ä¸“å®¶",
                    "agent_session_id": agent_session_id,
                    "status": "analyzing",
                    "status_msg": "æ­£åœ¨åˆ†æä¿®æ”¹éœ€æ±‚å¹¶ç”Ÿæˆä¿®æ”¹æŒ‡ä»¤...",
                    "need_feedback": False
                })
            
            # æ‰§è¡Œæ›´æ–°æ“ä½œ
            result = await self.update_patient_info(
                user_request=user_requirement,
                current_patient_data=current_patient_data,
                session_id=agent_session_id
            )
            
            if show_status_realtime and writer:
                # å‘é€å®ŒæˆçŠ¶æ€
                if "error" not in result:
                    # æˆåŠŸæƒ…å†µ
                    writer({
                        "type": "status",
                        "agent_name": "æ‚£è€…ä¿¡æ¯ä¿®æ”¹ä¸“å®¶",
                        "agent_session_id": agent_session_id,
                        "status": "completed",
                        "status_msg": "æ‚£è€…ä¿¡æ¯ä¿®æ”¹å®Œæˆ",
                        "need_feedback": False
                    })
                else:
                    # é”™è¯¯æƒ…å†µ
                    writer({
                        "type": "status",
                        "agent_name": "æ‚£è€…ä¿¡æ¯ä¿®æ”¹ä¸“å®¶",
                        "agent_session_id": agent_session_id,
                        "status": "error",
                        "status_msg": f"æ‚£è€…ä¿¡æ¯æ›´æ–°å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}",
                        "need_feedback": False
                    })
            
            return result
            
        except Exception as e:
            logger.error(f"Error in patient info update task: {e}")
            if show_status_realtime and writer:
                writer({
                    "type": "status",
                    "agent_name": "æ‚£è€…ä¿¡æ¯ä¿®æ”¹ä¸“å®¶",
                    "agent_session_id": agent_session_id,
                    "status": "error",
                    "status_msg": f"æ‚£è€…ä¿¡æ¯æ›´æ–°è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}",
                    "need_feedback": False
                })
            
            return {"error": str(e)} 