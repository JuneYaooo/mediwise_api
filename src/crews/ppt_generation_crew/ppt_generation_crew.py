import os
from dotenv import load_dotenv
load_dotenv()
from crewai import Agent, Crew, Process, Task
from crewai.project import CrewBase, agent, crew, task
from src.llms import *
from src.utils.json_utils import JsonUtils
from src.utils.logger import BeijingLogger
from datetime import datetime
from pathlib import Path
import uuid as uuid_lib
from src.custom_tools.suvalue_ppt_template_tool import SuvaluePPTTemplateTool
from src.custom_tools.suvalue_generate_ppt_tool import SuvalueGeneratePPTTool
from src.custom_tools.medical_ppt_generation_tool import MedicalPPTGenerationTool
from src.custom_tools.medical_ppt_template import get_template_by_id, list_available_templates
from src.custom_tools.patient_journey_image_generator import generate_patient_journey_image_sync
from src.custom_tools.indicator_chart_image_generator import generate_indicator_chart_images_multiple_sync
from src.custom_tools.treatment_data_processor import TreatmentDataProcessor
from src.custom_tools.treatment_gantt_chart_generator import generate_treatment_gantt_chart_sync
from app.utils.qiniu_upload_service import QiniuUploadService

# åˆå§‹åŒ– logger
logger = BeijingLogger().get_logger()


def process_raw_files_data(raw_files_data, filter_no_cropped_image=True):
    """
    å¤„ç†åŸå§‹æ–‡ä»¶æ•°æ®ï¼Œåªä¿ç•™éœ€è¦çš„å­—æ®µ

    PPTç”Ÿæˆç­–ç•¥ï¼š
    - å¦‚æœæœ‰è£å‰ªåçš„åŒ»å­¦å½±åƒå›¾ç‰‡(cropped_image_url)ï¼Œä¼˜å…ˆä½¿ç”¨è£å‰ªå›¾
    - å¦åˆ™ä½¿ç”¨åŸå§‹å›¾ç‰‡(cloud_storage_url)

    Args:
        raw_files_data (list): åŸå§‹æ–‡ä»¶æ•°æ®åˆ—è¡¨
        filter_no_cropped_image (bool): æ˜¯å¦è¿‡æ»¤æ‰cropped_image_availableä¸ºfalseçš„æ–‡ä»¶ï¼Œé»˜è®¤True

    Returns:
        list: å¤„ç†åçš„æ–‡ä»¶æ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åªåŒ…å«ï¼š
            - cloud_storage_url (PPTä¸­ä½¿ç”¨è£å‰ªå›¾æˆ–åŸå›¾)
            - exam_date
            - file_type
            - has_medical_image
            - extracted_text (å‰200ä¸ªå­—ç¬¦)
    """
    if not raw_files_data or not isinstance(raw_files_data, list):
        return []

    processed_data = []
    cropped_count = 0
    original_count = 0
    filtered_count = 0

    for file_item in raw_files_data:
        if not isinstance(file_item, dict):
            continue

        # PPTä¼˜å…ˆä½¿ç”¨è£å‰ªåçš„åŒ»å­¦å½±åƒ
        image_url = file_item.get("cloud_storage_url")
        cropped_image_available = file_item.get("cropped_image_available")
        cropped_image_url = file_item.get("cropped_image_url")
        filename = file_item.get("filename", "æœªçŸ¥æ–‡ä»¶")

        # ğŸš¨ DEBUG: è¾“å‡ºæ¯ä¸ªæ–‡ä»¶çš„è£å‰ªå›¾ä¿¡æ¯
        logger.info(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {filename}")
        logger.info(f"  â”œâ”€ has_medical_image: {file_item.get('has_medical_image', False)}")
        logger.info(f"  â”œâ”€ cropped_image_available: {cropped_image_available}")
        logger.info(f"  â”œâ”€ cropped_image_url: {cropped_image_url[:80] if cropped_image_url else None}...")
        logger.info(f"  â””â”€ cloud_storage_url: {image_url[:80] if image_url else None}...")

        # å¦‚æœå¯ç”¨è¿‡æ»¤ï¼Œåˆ™åªä¿ç•™cropped_image_available=Trueä¸”cropped_image_urlä¸ä¸ºç©ºçš„æ–‡ä»¶
        if filter_no_cropped_image:
            if not cropped_image_available or not cropped_image_url:
                filtered_count += 1
                logger.info(f"  âš ï¸ è¿‡æ»¤æ‰è¯¥æ–‡ä»¶ï¼ˆcropped_image_available={cropped_image_available}, cropped_image_url={'æœ‰' if cropped_image_url else 'æ— '}ï¼‰: {filename}")
                continue

        if cropped_image_available and cropped_image_url:
            image_url = cropped_image_url
            cropped_count += 1
            logger.info(f"  âœ… PPTä½¿ç”¨è£å‰ªå›¾: {filename} -> {image_url[:80]}...")
        else:
            original_count += 1
            logger.info(f"  â„¹ï¸ PPTä½¿ç”¨åŸå›¾: {filename}")

        processed_item = {
            "cloud_storage_url": image_url,  # ä½¿ç”¨è£å‰ªå›¾æˆ–åŸå›¾
            "exam_date": file_item.get("exam_date"),
            "file_type": file_item.get("file_type"),
            "has_medical_image": file_item.get("has_medical_image", False),
            "extracted_text": file_item.get("extracted_text", "")[:2000]  # åªå–å‰200ä¸ªå­—ç¬¦
        }
        processed_data.append(processed_item)

    logger.info("=" * 100)
    logger.info(f"ğŸ“Š PPTå›¾ç‰‡ä½¿ç”¨ç»Ÿè®¡: è£å‰ªå›¾ {cropped_count} ä¸ª, åŸå›¾ {original_count} ä¸ª, è¿‡æ»¤ {filtered_count} ä¸ª")
    logger.info("=" * 100)

    return processed_data


@CrewBase
class PPTGenerationCrew():
    """PPT generation crew - æ”¯æŒæœ¬åœ°ç”Ÿæˆå’ŒSuvalue APIä¸¤ç§æ¨¡å¼

    **ä¸¤ç§å·¥ä½œæµç¨‹**:
    1. **Agentæµç¨‹** (USE_AGENT_WORKFLOW=true)
       - ä½¿ç”¨CrewAI Agentè‡ªåŠ¨è°ƒç”¨å·¥å…·
       - é€‚åˆå¤æ‚çš„å¤šæ­¥éª¤ä»»åŠ¡
       - å¯èƒ½å‡ºç°JSONè§£æé—®é¢˜

    2. **ç›´æ¥LLMè°ƒç”¨** (USE_AGENT_WORKFLOW=false, é»˜è®¤)
       - LLMç”Ÿæˆæ•°æ® -> ç›´æ¥è°ƒç”¨å·¥å…·
       - æ›´ç¨³å®šã€æ›´å¯æ§
       - æ¨èä½¿ç”¨

    **ä½¿ç”¨æ–¹å¼**:
    ```python
    # æ–¹å¼1: é»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–
    crew = PPTGenerationCrew()

    # æ–¹å¼2: æ‰‹åŠ¨è®¾ç½®æ¨¡å¼
    PPTGenerationCrew.set_mode(
        use_suvalue_api=True,      # True=Suvalue API, False=æœ¬åœ°python-pptx
        use_agent_workflow=False   # False=ç›´æ¥LLMè°ƒç”¨(æ¨è), True=Agentæµç¨‹
    )
    ```

    **ç¯å¢ƒå˜é‡é…ç½®**:
    - USE_SUVALUE_PPT: true/false (é»˜è®¤true)
    - USE_AGENT_WORKFLOW: true/false (é»˜è®¤false)
    """

    agents_config = "config/agents.yaml"
    tasks_config = "config/tasks.yaml"

    # é»˜è®¤ä½¿ç”¨Suvalue APIï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
    _use_suvalue_api = os.getenv("USE_SUVALUE_PPT", "true").lower() in ("true", "1", "yes")

    # æ§åˆ¶æ˜¯å¦ä½¿ç”¨Agentæµç¨‹ï¼ˆé»˜è®¤Falseï¼Œä½¿ç”¨ç›´æ¥LLMè°ƒç”¨ï¼‰
    _use_agent_workflow = os.getenv("USE_AGENT_WORKFLOW", "false").lower() in ("true", "1", "yes")

    @classmethod
    def set_mode(cls, use_suvalue_api: bool, use_agent_workflow: bool = None):
        """è®¾ç½®PPTç”Ÿæˆæ¨¡å¼

        Args:
            use_suvalue_api: True=ä½¿ç”¨Suvalue API, False=ä½¿ç”¨æœ¬åœ°python-pptx
            use_agent_workflow: True=ä½¿ç”¨Agentæµç¨‹, False=ä½¿ç”¨ç›´æ¥LLMè°ƒç”¨ï¼ˆæ›´ç¨³å®šï¼‰ï¼ŒNone=ä¿æŒå½“å‰è®¾ç½®
        """
        cls._use_suvalue_api = use_suvalue_api
        if use_agent_workflow is not None:
            cls._use_agent_workflow = use_agent_workflow
        logger.info(f"PPTGenerationCrew æ¨¡å¼: {'Suvalue API' if use_suvalue_api else 'æœ¬åœ°python-pptx'}, "
                   f"å·¥ä½œæµ: {'Agentæµç¨‹' if cls._use_agent_workflow else 'ç›´æ¥LLMè°ƒç”¨'}")

    @agent
    def ppt_content_generator(self) -> Agent:
        """æœ¬åœ°æ¨¡å¼çš„agent"""
        return Agent(
            config=self.agents_config['ppt_content_generator'],
            llm=document_generation_llm,
            tools=[MedicalPPTGenerationTool()],
            verbose=True
        )

    @agent
    def suvalue_ppt_data_transformer(self) -> Agent:
        """Suvalue APIæ¨¡å¼çš„agent"""
        return Agent(
            config=self.agents_config['suvalue_ppt_data_transformer'],
            llm=document_generation_llm,
            tools=[SuvaluePPTTemplateTool(), SuvalueGeneratePPTTool()],
            verbose=True
        )

    def _generate_ppt_data_with_llm(self, patient_timeline, raw_files_data, patient_name,
                                     patient_journey_image_url, indicator_chart_images,
                                     treatment_gantt_chart_url, treatment_gantt_data=None, template_type=2):
        """
        ä½¿ç”¨LLMç›´æ¥ç”ŸæˆPPTæ•°æ®ï¼ˆä¸ä½¿ç”¨Agentæµç¨‹ï¼‰

        Args:
            patient_timeline: æ‚£è€…æ—¶é—´è½´æ•°æ®
            raw_files_data: åŸå§‹æ–‡ä»¶æ•°æ®
            patient_name: æ‚£è€…å§“å
            patient_journey_image_url: æ‚£è€…æ—¶é—´æ—…ç¨‹å›¾ç‰‡URL
            indicator_chart_images: æ ¸å¿ƒæŒ‡æ ‡è¶‹åŠ¿å›¾ç‰‡åˆ—è¡¨
            treatment_gantt_chart_url: æ²»ç–—ç”˜ç‰¹å›¾URL
            treatment_gantt_data: æ²»ç–—ç”˜ç‰¹å›¾æ•°æ®åˆ—è¡¨ï¼ˆsource_file å·²æ›¿æ¢ä¸ºæ–‡ä»¶åï¼‰
            template_type: æ¨¡æ¿ç±»å‹ï¼ˆé»˜è®¤2ï¼‰

        Returns:
            dict: æ ¼å¼åŒ–çš„PPTæ•°æ®ï¼Œå¯ç›´æ¥ä¼ ç»™SuvalueGeneratePPTTool
        """
        try:
            logger.info("ä½¿ç”¨LLMç›´æ¥ç”ŸæˆPPTæ•°æ®ï¼ˆç»•è¿‡Agentæµç¨‹ï¼‰")

            # 1. è·å–æ¨¡æ¿ä¿¡æ¯
            template_tool = SuvaluePPTTemplateTool()
            template_info = template_tool._run(template_type=template_type)

            if not template_info or not template_info.get("success"):
                error_msg = template_info.get("error", "è·å–æ¨¡æ¿ä¿¡æ¯å¤±è´¥") if template_info else "è·å–æ¨¡æ¿ä¿¡æ¯å¤±è´¥"
                logger.error(f"è·å–Suvalueæ¨¡æ¿ä¿¡æ¯å¤±è´¥: {error_msg}")
                return None

            # æ¨¡æ¿JSONåœ¨ template_json å­—æ®µä¸­ï¼ˆåŒ…å«æ³¨é‡Šçš„åŸå§‹æ¨¡æ¿ï¼‰
            template_json_str = template_info.get("template_json", "{}")
            logger.info(f"æˆåŠŸè·å–æ¨¡æ¿JSONå­—ç¬¦ä¸²ï¼Œé•¿åº¦: {len(template_json_str)}")

            # ä¸éœ€è¦è§£æJSONï¼Œç›´æ¥å°†åŸå§‹æ¨¡æ¿ï¼ˆåŒ…å«æ³¨é‡Šï¼‰ä¼ ç»™LLM
            # LLMèƒ½ç†è§£JSONä¸­çš„æ³¨é‡Šè¯´æ˜

            # 2. æ„å»ºæç¤ºè¯
            import json

            # æ„å»ºæ²»ç–—ç”˜ç‰¹å›¾æ•°æ®è¯´æ˜
            treatment_gantt_data_str = ""
            if treatment_gantt_data:
                treatment_gantt_data_str = f"\n\n**æ²»ç–—ç”˜ç‰¹å›¾æ•°æ®** (åŒ…å«æ¯æ¡æ²»ç–—çš„è¯¦ç»†ä¿¡æ¯ï¼Œsource_file å·²æ›¿æ¢ä¸ºæ–‡ä»¶å):\n{json.dumps(treatment_gantt_data, ensure_ascii=False, indent=2)}"

            prompt = f"""ä½ æ˜¯ä¸€ä¸ªåŒ»ç–—æ•°æ®è½¬æ¢ä¸“å®¶ï¼Œéœ€è¦å°†æ‚£è€…æ•°æ®è½¬æ¢ä¸ºSuvalue PPTæ¨¡æ¿æ ¼å¼ã€‚

**ä»»åŠ¡**: æ ¹æ®ä¸‹é¢çš„æ¨¡æ¿å­—æ®µè¯´æ˜å’Œæ‚£è€…æ•°æ®ï¼Œç”Ÿæˆç¬¦åˆæ¨¡æ¿è¦æ±‚çš„JSONæ•°æ®ã€‚

**æ¨¡æ¿å­—æ®µè¯´æ˜**ï¼ˆåŒ…å«æ³¨é‡Šè¯´æ˜æ¯ä¸ªå­—æ®µçš„ç”¨é€”ï¼‰:
{template_json_str}

**æ‚£è€…æ•°æ®**:
æ‚£è€…å§“å: {patient_name}
æ‚£è€…æ—¶é—´è½´æ•°æ®: {json.dumps(patient_timeline, ensure_ascii=False)}
åŸå§‹æ–‡ä»¶æ•°æ®: {json.dumps(raw_files_data, ensure_ascii=False)}\n\n{treatment_gantt_data_str}

**é¢„ç”Ÿæˆçš„å›¾è¡¨URL** (ä¼˜å…ˆä½¿ç”¨è¿™äº›):
- æ‚£è€…æ—¶é—´æ—…ç¨‹å›¾: {patient_journey_image_url or "æœªç”Ÿæˆ"}
- æ ¸å¿ƒæŒ‡æ ‡è¶‹åŠ¿å›¾: {json.dumps(indicator_chart_images, ensure_ascii=False) if indicator_chart_images else "æœªç”Ÿæˆ"}
- æ²»ç–—ç”˜ç‰¹å›¾: {treatment_gantt_chart_url or "æœªç”Ÿæˆ"}

**é‡è¦è¦æ±‚**:
1. ä¸¥æ ¼æŒ‰ç…§æ¨¡æ¿ç»“æ„è¾“å‡ºï¼Œä¸è¦æ·»åŠ æˆ–åˆ é™¤å­—æ®µ
2. åªä½¿ç”¨æ‚£è€…æ•°æ®ä¸­çœŸå®å­˜åœ¨çš„ä¿¡æ¯ï¼Œä¸è¦ç¼–é€ 
3. å¯¹äºåŒ»å­¦åŸå§‹æ–‡ä»¶çš„å›¾åƒï¼Œä»[åŸå§‹æ–‡ä»¶æ•°æ®]ä¸­é€‰æ‹©has_medical_image=trueçš„å›¾ç‰‡ï¼ˆä¼˜å…ˆé€‰æ‹©è£å‰ªå›¾ï¼‰
4. æ²»ç–—æ•°æ®å¯ä»[æ²»ç–—ç”˜ç‰¹å›¾æ•°æ®]ä¸­è·å–ï¼Œå…¶ä¸­source_fileå­—æ®µå·²æ˜¯æ–‡ä»¶åï¼ˆä¸æ˜¯UUIDï¼‰
5. ç¡®ä¿æ‰€æœ‰å›¾ç‰‡URLæ˜¯å®Œæ•´çš„ï¼ˆåŒ…å«http://æˆ–https://ï¼‰
6. ç›´æ¥è¾“å‡ºJSONæ ¼å¼ï¼Œå»é™¤æ¨¡æ¿ä¸­çš„æ‰€æœ‰æ³¨é‡Š
7. ä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæ–‡å­—ã€Markdownä»£ç å—æ ‡è®°ï¼ˆå¦‚```jsonï¼‰

è¯·è¾“å‡ºç¬¦åˆæ¨¡æ¿è¦æ±‚çš„JSONæ•°æ®:"""

            # 3. è°ƒç”¨LLM
            logger.info("è°ƒç”¨LLMç”ŸæˆPPTæ•°æ®...")
            try:
                # CrewAI LLM å¯¹è±¡ç›´æ¥è°ƒç”¨
                response = document_generation_llm.call(prompt)
                response_text = str(response)
            except AttributeError:
                # å¦‚æœæ˜¯ LangChain LLMï¼Œä½¿ç”¨ invoke
                try:
                    response = document_generation_llm.invoke(prompt)
                    response_text = response.content if hasattr(response, 'content') else str(response)
                except Exception as e:
                    logger.error(f"LLMè°ƒç”¨å¤±è´¥: {e}")
                    return None

            # 4. æå–JSON
            logger.info(f"LLMå“åº”é•¿åº¦: {len(response_text)}")
            logger.info(f"LLMå“åº”å‰500å­—ç¬¦: {response_text[:500]}")

            # ä½¿ç”¨JsonUtilsæå–JSON
            ppt_data = JsonUtils.safe_parse_json(response_text, debug_prefix="LLMç”ŸæˆPPTæ•°æ®")

            if not ppt_data:
                logger.error("æ— æ³•ä»LLMå“åº”ä¸­æå–æœ‰æ•ˆJSON")
                return None

            # æ£€æŸ¥LLMè¿”å›çš„ç»“æ„ï¼Œæå–å®é™…çš„PPTæ•°æ®
            # LLMå¯èƒ½è¿”å›åŒ…è£…ç»“æ„ï¼š{"success": true, "template_json": "..."}
            # æˆ–è€…ç›´æ¥è¿”å›PPTæ•°æ®ï¼š{"pptTemplate2Vm": {...}}
            if "template_json" in ppt_data:
                # å¦‚æœæœ‰template_jsonå­—æ®µï¼Œéœ€è¦å†è§£æä¸€æ¬¡
                logger.info("æ£€æµ‹åˆ°template_jsonå­—æ®µï¼Œè¿›è¡ŒäºŒæ¬¡è§£æ...")
                template_json_str = ppt_data.get("template_json", "{}")
                ppt_data = JsonUtils.safe_parse_json(template_json_str, debug_prefix="äºŒæ¬¡è§£æPPTæ•°æ®")
                if not ppt_data:
                    logger.error("äºŒæ¬¡è§£æå¤±è´¥")
                    return None

            # éªŒè¯æ˜¯å¦åŒ…å«pptTemplate2Vmå­—æ®µ
            if "pptTemplate2Vm" not in ppt_data:
                logger.error(f"PPTæ•°æ®ç¼ºå°‘pptTemplate2Vmå­—æ®µï¼Œå½“å‰é¡¶å±‚å­—æ®µ: {list(ppt_data.keys())}")
                # å¦‚æœé¡¶å±‚å°±æ˜¯pptTemplate2Vmçš„å†…å®¹ï¼ŒåŒ…è£…ä¸€ä¸‹
                if any(key in ppt_data for key in ["title", "patient", "diag"]):
                    logger.info("æ£€æµ‹åˆ°é¡¶å±‚åŒ…å«PPTå­—æ®µï¼Œè‡ªåŠ¨åŒ…è£…ä¸ºpptTemplate2Vmç»“æ„")
                    ppt_data = {"pptTemplate2Vm": ppt_data}
                else:
                    return None

            logger.info(f"âœ… æˆåŠŸç”ŸæˆPPTæ•°æ®ç»“æ„")
            logger.info(f"ğŸ“¦ pptTemplate2Vm åŒ…å«å­—æ®µ: {list(ppt_data.get('pptTemplate2Vm', {}).keys())[:10]}")
            return ppt_data

        except Exception as e:
            logger.error(f"ä½¿ç”¨LLMç”ŸæˆPPTæ•°æ®æ—¶å‡ºé”™: {e}", exc_info=True)
            return None

    @task
    def generate_ppt_slides_task(self) -> Task:
        """æœ¬åœ°æ¨¡å¼çš„task"""
        return Task(
            config=self.tasks_config['generate_ppt_slides_task']
        )

    @task
    def transform_and_generate_ppt_task(self) -> Task:
        """Suvalue APIæ¨¡å¼çš„task"""
        return Task(
            config=self.tasks_config['transform_and_generate_ppt_task']
        )

    @crew
    def crew(self) -> Crew:
        """Creates the PPT generation crew"""
        # æ ¹æ®æ¨¡å¼é€‰æ‹©ä¸åŒçš„ agents å’Œ tasks
        if self._use_suvalue_api:
            agents = [self.suvalue_ppt_data_transformer()]
            tasks = [self.transform_and_generate_ppt_task()]
        else:
            agents = [self.ppt_content_generator()]
            tasks = [self.generate_ppt_slides_task()]

        return Crew(
            agents=agents,
            tasks=tasks,
            process=Process.sequential,
            verbose=True
        )

    def generate_ppt(self, patient_timeline, patient_journey, raw_files_data, agent_session_id,
                     auth_token=None, template_id="medical", filter_no_cropped_image=True):
        """
        Generate PPT from patient data

        æ ¹æ®åˆå§‹åŒ–æ—¶çš„ use_suvalue_api å‚æ•°é€‰æ‹©ç”Ÿæˆæ–¹å¼ï¼š
        - True: ä½¿ç”¨Suvalue APIç”Ÿæˆï¼ˆéœ€è¦auth_tokenï¼‰
        - False: ä½¿ç”¨æœ¬åœ°python-pptxç”Ÿæˆï¼ˆéœ€è¦template_idï¼‰

        Args:
            patient_timeline (dict or list): Patient timeline data for PPT content generation
            patient_journey (dict or list): Patient journey data for image generation (timeline chart, indicator trends)
            raw_files_data (list): Raw files data (will be processed to keep only required fields)
            agent_session_id (str): Session ID for file organization
            auth_token (str, optional): Bearer token for Suvalue API authentication (Suvalueæ¨¡å¼å¿…éœ€)
            template_id (str, optional): PPT template ID for local generation (æœ¬åœ°æ¨¡å¼å¿…éœ€, default: "medical")
            filter_no_cropped_image (bool, optional): æ˜¯å¦è¿‡æ»¤æ‰cropped_image_availableä¸ºfalseçš„æ–‡ä»¶ï¼Œé»˜è®¤True

        Returns:
            dict: PPT info
                - Suvalueæ¨¡å¼: {"success": bool, "ppt_url": str, "message": str}
                - æœ¬åœ°æ¨¡å¼: {"success": bool, "local_path": str, "file_uuid": str, "qiniu_url": str}
        """
        try:
            if self._use_suvalue_api:
                logger.info("Starting Suvalue PPT generation task (API mode)")
            else:
                logger.info("Starting Local PPT generation task (python-pptx mode)")
            current_date = datetime.now().strftime("%Y-%m-%d")

            # å¤„ç† raw_files_dataï¼Œåªä¿ç•™éœ€è¦çš„å­—æ®µ
            processed_raw_files_data = process_raw_files_data(raw_files_data, filter_no_cropped_image=filter_no_cropped_image)
            logger.info(f"å¤„ç†äº† {len(processed_raw_files_data)} ä¸ªæ–‡ä»¶çš„å…ƒæ•°æ®ï¼ˆä»…ä¿ç•™PPTæ‰€éœ€å­—æ®µï¼‰")

            # è·å–æ‚£è€…å§“å
            patient_name = 'æ‚£è€…'
            if isinstance(patient_journey, dict):
                # ä» patient_journey ä¸­è·å–æ‚£è€…å§“å
                if 'patient_info' in patient_journey:
                    patient_info = patient_journey.get('patient_info', {})
                    if isinstance(patient_info, dict):
                        basic_info = patient_info.get('basic', {})
                        if isinstance(basic_info, dict):
                            patient_name = basic_info.get('name', 'æ‚£è€…')
            elif isinstance(patient_journey, list) and patient_journey:
                # å¦‚æœæ˜¯åˆ—è¡¨æ ¼å¼ï¼Œå°è¯•ä»ç¬¬ä¸€ä¸ªæ¡ç›®è·å–æ‚£è€…å§“å
                first_entry = patient_journey[0]
                if isinstance(first_entry, dict):
                    patient_name = first_entry.get('patient_name', 'æ‚£è€…')

            logger.info(f"Patient name: {patient_name}")

            # ========== ç”Ÿæˆæ‚£è€…æ—¶é—´æ—…ç¨‹å›¾ç‰‡å¹¶ä¸Šä¼ åˆ°ä¸ƒç‰›äº‘ ==========
            patient_journey_image_url = None
            patient_journey_image_path = None

            # æå–æ—¶é—´çº¿æ•°æ®
            timeline_data = None
            if patient_journey:
                if isinstance(patient_journey, dict):
                    # å¦‚æœæ˜¯å­—å…¸ï¼Œå°è¯•æå–timeline_journeyå­—æ®µ
                    timeline_data = patient_journey.get('timeline_journey', patient_journey)
                elif isinstance(patient_journey, list):
                    # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œç›´æ¥ä½¿ç”¨
                    timeline_data = patient_journey

            if timeline_data:
                try:
                    # æ”¯æŒåˆ—è¡¨æ ¼å¼
                    if isinstance(timeline_data, list) and timeline_data:
                        logger.info("å¼€å§‹ç”Ÿæˆæ‚£è€…æ—¶é—´æ—…ç¨‹å›¾ç‰‡ï¼ˆç”¨äºPPTï¼‰...")

                        # ç”Ÿæˆå›¾ç‰‡æ–‡ä»¶åå’Œè·¯å¾„
                        image_uuid = str(uuid_lib.uuid4())
                        output_dir = Path("output/files_extract") / agent_session_id / "ppt_images"
                        output_dir.mkdir(parents=True, exist_ok=True)

                        image_filename = f"patient_journey_{image_uuid}.png"
                        image_path = output_dir / image_filename

                        # ç”Ÿæˆå›¾ç‰‡
                        success = generate_patient_journey_image_sync(
                            patient_journey_data=timeline_data,
                            output_path=str(image_path),
                            patient_name=patient_name
                        )

                        if success and image_path.exists():
                            patient_journey_image_path = str(image_path)
                            logger.info(f"æ‚£è€…æ—¶é—´æ—…ç¨‹å›¾ç‰‡ç”ŸæˆæˆåŠŸ: {patient_journey_image_path}")

                            # ä¸Šä¼ åˆ°ä¸ƒç‰›äº‘
                            try:
                                qiniu_service = QiniuUploadService()
                                qiniu_key = f"patient_journey_ppt/{image_uuid}.png"

                                upload_success, cloud_url, error = qiniu_service.upload_file(
                                    str(image_path),
                                    qiniu_key
                                )

                                if upload_success:
                                    patient_journey_image_url = cloud_url
                                    logger.info(f"æ‚£è€…æ—¶é—´æ—…ç¨‹å›¾ç‰‡å·²ä¸Šä¼ åˆ°ä¸ƒç‰›äº‘: {cloud_url}")
                                else:
                                    logger.error(f"ä¸Šä¼ æ‚£è€…æ—¶é—´æ—…ç¨‹å›¾ç‰‡åˆ°ä¸ƒç‰›äº‘å¤±è´¥: {error}")
                            except Exception as upload_error:
                                logger.error(f"ä¸Šä¼ æ‚£è€…æ—¶é—´æ—…ç¨‹å›¾ç‰‡åˆ°ä¸ƒç‰›äº‘æ—¶å‡ºé”™: {upload_error}")
                        else:
                            logger.warning("æ‚£è€…æ—¶é—´æ—…ç¨‹å›¾ç‰‡ç”Ÿæˆå¤±è´¥")
                    else:
                        logger.info("æ‚£è€…æ—…ç¨‹æ•°æ®ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®ï¼Œè·³è¿‡å›¾ç‰‡ç”Ÿæˆ")

                except Exception as e:
                    logger.error(f"ç”Ÿæˆæˆ–ä¸Šä¼ æ‚£è€…æ—¶é—´æ—…ç¨‹å›¾ç‰‡æ—¶å‡ºé”™: {e}")
                    import traceback
                    logger.error(traceback.format_exc())

            # ========== ç”Ÿæˆæ ¸å¿ƒæŒ‡æ ‡è¶‹åŠ¿å›¾ç‰‡å¹¶ä¸Šä¼ åˆ°ä¸ƒç‰›äº‘ ==========
            indicator_chart_images = []  # å­˜å‚¨å¤šä¸ªæŒ‡æ ‡å›¾ç‰‡çš„ä¿¡æ¯
            if patient_journey:
                try:
                    # æ£€æŸ¥æ˜¯å¦æœ‰indicator_seriesæ•°æ®
                    indicator_series = None
                    if isinstance(patient_journey, dict) and 'indicator_series' in patient_journey:
                        indicator_series = patient_journey.get('indicator_series')

                    if indicator_series and isinstance(indicator_series, list) and indicator_series:
                        logger.info(f"å¼€å§‹ç”Ÿæˆæ ¸å¿ƒæŒ‡æ ‡è¶‹åŠ¿å›¾ç‰‡ï¼ˆç”¨äºPPTï¼‰ï¼ŒåŒ…å« {len(indicator_series)} ä¸ªæŒ‡æ ‡ï¼Œæ¯ä¸ªæŒ‡æ ‡å•ç‹¬ç”Ÿæˆå›¾ç‰‡...")

                        # ç”Ÿæˆå›¾ç‰‡ç›®å½•
                        output_dir = Path("output/files_extract") / agent_session_id / "ppt_images" / "indicators"
                        output_dir.mkdir(parents=True, exist_ok=True)

                        # ä¸ºæ¯ä¸ªæŒ‡æ ‡ç”Ÿæˆç‹¬ç«‹çš„å›¾ç‰‡
                        results = generate_indicator_chart_images_multiple_sync(
                            indicator_series_data=indicator_series,
                            output_dir=str(output_dir),
                            patient_name=patient_name
                        )

                        # ä¸Šä¼ æ¯ä¸ªå›¾ç‰‡åˆ°ä¸ƒç‰›äº‘
                        qiniu_service = QiniuUploadService()
                        for result in results:
                            if result['success'] and result['file_path']:
                                try:
                                    # ç”Ÿæˆå”¯ä¸€çš„ä¸ƒç‰›äº‘key
                                    file_path = Path(result['file_path'])
                                    image_uuid = str(uuid_lib.uuid4())
                                    qiniu_key = f"indicator_chart_ppt/{image_uuid}_{file_path.name}"

                                    upload_success, cloud_url, error = qiniu_service.upload_file(
                                        result['file_path'],
                                        qiniu_key
                                    )

                                    if upload_success:
                                        indicator_chart_images.append({
                                            "indicator_name": result['indicator_name'],
                                            "local_path": result['file_path'],
                                            "cloud_url": cloud_url
                                        })
                                        logger.info(f"æŒ‡æ ‡ '{result['indicator_name']}' å›¾ç‰‡å·²ä¸Šä¼ åˆ°ä¸ƒç‰›äº‘: {cloud_url}")
                                    else:
                                        logger.error(f"ä¸Šä¼ æŒ‡æ ‡ '{result['indicator_name']}' å›¾ç‰‡åˆ°ä¸ƒç‰›äº‘å¤±è´¥: {error}")
                                        # å³ä½¿ä¸Šä¼ å¤±è´¥ï¼Œä¹Ÿä¿ç•™æœ¬åœ°è·¯å¾„
                                        indicator_chart_images.append({
                                            "indicator_name": result['indicator_name'],
                                            "local_path": result['file_path'],
                                            "cloud_url": None
                                        })
                                except Exception as upload_error:
                                    logger.error(f"ä¸Šä¼ æŒ‡æ ‡ '{result['indicator_name']}' å›¾ç‰‡åˆ°ä¸ƒç‰›äº‘æ—¶å‡ºé”™: {upload_error}")
                                    indicator_chart_images.append({
                                        "indicator_name": result['indicator_name'],
                                        "local_path": result['file_path'],
                                        "cloud_url": None
                                    })

                        logger.info(f"æ ¸å¿ƒæŒ‡æ ‡è¶‹åŠ¿å›¾ç‰‡ç”Ÿæˆå®Œæˆï¼ŒæˆåŠŸç”Ÿæˆ {len(indicator_chart_images)} ä¸ªå›¾ç‰‡")
                    else:
                        logger.info("æŒ‡æ ‡åºåˆ—æ•°æ®ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®ï¼Œè·³è¿‡å›¾ç‰‡ç”Ÿæˆ")

                except Exception as e:
                    logger.error(f"ç”Ÿæˆæˆ–ä¸Šä¼ æ ¸å¿ƒæŒ‡æ ‡è¶‹åŠ¿å›¾ç‰‡æ—¶å‡ºé”™: {e}")
                    import traceback
                    logger.error(traceback.format_exc())

            # ========== å¤„ç†æ²»ç–—ç”˜ç‰¹å›¾æ•°æ®å¹¶ç”Ÿæˆå›¾ç‰‡ä¸Šä¼ åˆ°ä¸ƒç‰›äº‘ ==========
            #
            # æ²»ç–—ç”˜ç‰¹å›¾æ•°æ®å¤„ç†æµç¨‹ï¼š
            # 1. ä» patient_timeline æˆ– patient_journey ä¸­æå–æ²»ç–—æ•°æ®
            # 2. ä½¿ç”¨ TreatmentDataProcessor å¤„ç†æ•°æ®ï¼Œç”Ÿæˆç”˜ç‰¹å›¾æ‰€éœ€æ ¼å¼ (gantt_data)
            # 3. æ„å»º file_uuid -> filename æ˜ å°„ï¼Œå°† gantt_data ä¸­çš„ source_file (UUID) æ›¿æ¢ä¸ºæ–‡ä»¶å
            # 4. è°ƒç”¨ generate_treatment_gantt_chart_sync ç”Ÿæˆç”˜ç‰¹å›¾å›¾ç‰‡ (ä½¿ç”¨ ECharts æœ¬åœ°æ¸²æŸ“)
            # 5. ä¸Šä¼ å›¾ç‰‡åˆ°ä¸ƒç‰›äº‘ï¼Œè·å– treatment_gantt_chart_url
            #
            # gantt_data æ•°æ®ç»“æ„ç¤ºä¾‹ï¼ˆå¤„ç†åçš„åŸå§‹æ•°æ®ï¼Œå¯ç›´æ¥ä¼ ç»™PPTæ¨¡æ¿ï¼‰ï¼š
            # [
            #   {
            #     "treatment_name": "æ²»ç–—åç§°",           # æ²»ç–—æ–¹æ¡ˆåç§°
            #     "start_date": "2024-01-01",           # å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            #     "end_date": "2024-01-15",             # ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            #     "category": "åŒ–ç–—/æ”¾ç–—/æ‰‹æœ¯/é¶å‘æ²»ç–—ç­‰", # æ²»ç–—ç±»åˆ«
            #     "source_file": "æ¥æºæ–‡ä»¶å.pdf",       # æ¥æºæ–‡ä»¶åï¼ˆå·²ä»UUIDè½¬æ¢ï¼‰
            #     "details": "æ²»ç–—è¯¦æƒ…æè¿°"              # æ²»ç–—è¯¦ç»†ä¿¡æ¯
            #   },
            #   ...
            # ]
            #
            treatment_gantt_chart_url = None
            treatment_gantt_chart_path = None
            source_file_mapping = {}  # å­˜å‚¨ file_uuid -> filename çš„æ˜ å°„

            if patient_timeline or patient_journey:
                try:
                    logger.info("å¼€å§‹å¤„ç†æ‚£è€…æ²»ç–—æ•°æ®å¹¶ç”Ÿæˆç”˜ç‰¹å›¾...")

                    # åˆå§‹åŒ–æ²»ç–—æ•°æ®å¤„ç†å™¨
                    treatment_processor = TreatmentDataProcessor()

                    # ä»patient_timelineæˆ–patient_journeyä¸­æå–æ²»ç–—æ•°æ®
                    # ä¼˜å…ˆä½¿ç”¨patient_timelineï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨patient_journey
                    source_data = patient_timeline if patient_timeline else patient_journey

                    # è°ƒè¯•ï¼šæ£€æŸ¥æ•°æ®ç±»å‹å’Œå†…å®¹
                    logger.info(f"æ²»ç–—æ•°æ®æºç±»å‹: {type(source_data)}")
                    if isinstance(source_data, str):
                        logger.info(f"æ•°æ®æ˜¯å­—ç¬¦ä¸²ï¼Œé•¿åº¦: {len(source_data)}, å‰200å­—ç¬¦: {source_data[:200]}")
                    elif isinstance(source_data, dict):
                        logger.info(f"æ•°æ®æ˜¯å­—å…¸ï¼Œé”®: {list(source_data.keys())[:10]}")
                    elif isinstance(source_data, list):
                        logger.info(f"æ•°æ®æ˜¯åˆ—è¡¨ï¼Œé•¿åº¦: {len(source_data)}")

                    # å¤„ç†æ²»ç–—æ•°æ®ç”Ÿæˆç”˜ç‰¹å›¾æ‰€éœ€æ ¼å¼
                    gantt_data = treatment_processor.process_patient_treatments(source_data)

                    if gantt_data and len(gantt_data) > 0:
                        logger.info(f"æˆåŠŸæå– {len(gantt_data)} æ¡æ²»ç–—è®°å½•ï¼Œå¼€å§‹ç”Ÿæˆç”˜ç‰¹å›¾...")
                        logger.info(f"ç”˜ç‰¹å›¾æ•°æ®: {gantt_data}")

                        # æ„å»º source_file (file_uuid) -> filename çš„æ˜ å°„
                        if raw_files_data and isinstance(raw_files_data, list):
                            for file_item in raw_files_data:
                                if isinstance(file_item, dict):
                                    file_uuid = file_item.get("file_uuid")
                                    filename = file_item.get("filename")
                                    if file_uuid and filename:
                                        source_file_mapping[file_uuid] = filename
                            logger.info(f"æ„å»ºäº† {len(source_file_mapping)} ä¸ªæ–‡ä»¶æ˜ å°„å…³ç³»")

                        # æ›¿æ¢ gantt_data ä¸­çš„ source_file (UUID) ä¸º source_file_name (æ–‡ä»¶å)
                        for treatment in gantt_data:
                            source_file_uuid = treatment.get("source_file", "")
                            if source_file_uuid and source_file_uuid in source_file_mapping:
                                treatment["source_file"] = source_file_mapping[source_file_uuid]
                            else:
                                treatment["source_file"] = ""

                        logger.info("å·²å°†æ²»ç–—è®°å½•çš„ source_file ä» UUID æ›¿æ¢ä¸ºæ–‡ä»¶å")

                        # ç”Ÿæˆå›¾ç‰‡æ–‡ä»¶åå’Œè·¯å¾„
                        gantt_uuid = str(uuid_lib.uuid4())
                        output_dir = Path("output/files_extract") / agent_session_id / "ppt_images"
                        output_dir.mkdir(parents=True, exist_ok=True)

                        gantt_filename = f"treatment_gantt_{gantt_uuid}.png"
                        gantt_path = output_dir / gantt_filename

                        # ç”Ÿæˆç”˜ç‰¹å›¾å›¾ç‰‡ï¼ˆä½¿ç”¨ECharts - æœ¬åœ°æ¸²æŸ“ï¼Œæ— éœ€è”ç½‘ï¼‰
                        success = generate_treatment_gantt_chart_sync(
                            gantt_data=gantt_data,
                            output_path=str(gantt_path),
                            patient_name=patient_name,
                            use_google_charts=False  # ä½¿ç”¨EChartsï¼Œæ¯æ¡æ²»ç–—è®°å½•ç‹¬ç«‹æ˜¾ç¤º
                        )

                        if success and gantt_path.exists():
                            treatment_gantt_chart_path = str(gantt_path)
                            logger.info(f"æ²»ç–—ç”˜ç‰¹å›¾ç”ŸæˆæˆåŠŸ: {treatment_gantt_chart_path}")

                            # ä¸Šä¼ åˆ°ä¸ƒç‰›äº‘
                            try:
                                qiniu_service = QiniuUploadService()
                                qiniu_key = f"treatment_gantt_ppt/{gantt_uuid}.png"

                                upload_success, cloud_url, error = qiniu_service.upload_file(
                                    str(gantt_path),
                                    qiniu_key
                                )

                                if upload_success:
                                    treatment_gantt_chart_url = cloud_url
                                    logger.info(f"æ²»ç–—ç”˜ç‰¹å›¾å·²ä¸Šä¼ åˆ°ä¸ƒç‰›äº‘: {cloud_url}")
                                else:
                                    logger.error(f"ä¸Šä¼ æ²»ç–—ç”˜ç‰¹å›¾åˆ°ä¸ƒç‰›äº‘å¤±è´¥: {error}")
                            except Exception as upload_error:
                                logger.error(f"ä¸Šä¼ æ²»ç–—ç”˜ç‰¹å›¾åˆ°ä¸ƒç‰›äº‘æ—¶å‡ºé”™: {upload_error}")
                        else:
                            logger.warning("æ²»ç–—ç”˜ç‰¹å›¾ç”Ÿæˆå¤±è´¥")
                    else:
                        logger.info("æœªæå–åˆ°æ²»ç–—æ•°æ®ï¼Œè·³è¿‡ç”˜ç‰¹å›¾ç”Ÿæˆ")

                except Exception as e:
                    logger.error(f"ç”Ÿæˆæˆ–ä¸Šä¼ æ²»ç–—ç”˜ç‰¹å›¾æ—¶å‡ºé”™: {e}")
                    import traceback
                    logger.error(traceback.format_exc())

            # ç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½æ˜¯JSONå¯åºåˆ—åŒ–çš„
            import json

            # è½¬æ¢æ•°æ®ä¸ºJSONå­—ç¬¦ä¸²ä»¥ç¡®ä¿å¯åºåˆ—åŒ–
            try:
                patient_timeline_json = json.dumps(patient_timeline, ensure_ascii=False, default=str)
                processed_files_json = json.dumps(processed_raw_files_data, ensure_ascii=False, default=str)
                # æ–°å¢ï¼šåºåˆ—åŒ– treatment_gantt_data (å·²åŒ…å« source_file æ–‡ä»¶å)
                treatment_gantt_data_json = json.dumps(gantt_data if 'gantt_data' in locals() else [], ensure_ascii=False, default=str)
            except Exception as e:
                logger.error(f"JSONåºåˆ—åŒ–å¤±è´¥: {str(e)}")
                return {"success": False, "error": f"æ•°æ®åºåˆ—åŒ–å¤±è´¥: {str(e)}"}

            # æ ¹æ®æ¨¡å¼å‡†å¤‡ä¸åŒçš„è¾“å…¥å‚æ•°
            if self._use_suvalue_api:
                # Suvalue APIæ¨¡å¼
                ppt_inputs = {
                    "current_date": current_date,
                    "patient_timeline": patient_timeline_json,
                    "raw_files_data": processed_files_json,
                    "patient_name": patient_name,
                    "auth_token": auth_token or "",  # å…è®¸ä¸ºç©º
                    "session_id": agent_session_id,
                    "patient_journey_image_url": patient_journey_image_url or "",
                    "indicator_chart_images": json.dumps(indicator_chart_images, ensure_ascii=False),
                    "treatment_gantt_chart_url": treatment_gantt_chart_url or "",
                    "treatment_gantt_data": treatment_gantt_data_json  # æ–°å¢ï¼šæ²»ç–—ç”˜ç‰¹å›¾æ•°æ®ï¼ˆsource_file å·²æ›¿æ¢ä¸ºæ–‡ä»¶åï¼‰
                }
            else:
                # æœ¬åœ°æ¨¡å¼
                logger.info(f"Retrieving medical template information for: {template_id}")
                template_info = get_template_by_id(template_id)

                if not template_info:
                    logger.error(f"Failed to retrieve template: {template_id}")
                    return {"success": False, "error": f"Template not found: {template_id}"}

                logger.info(f"Successfully retrieved template: {template_info.get('name')}")

                try:
                    template_info_json = json.dumps(template_info, ensure_ascii=False, default=str)
                except Exception as e:
                    logger.error(f"æ¨¡æ¿ä¿¡æ¯JSONåºåˆ—åŒ–å¤±è´¥: {str(e)}")
                    return {"success": False, "error": f"æ¨¡æ¿ä¿¡æ¯åºåˆ—åŒ–å¤±è´¥: {str(e)}"}

                ppt_inputs = {
                    "current_date": current_date,
                    "patient_structured_data": patient_timeline_json,
                    "patient_timeline": patient_timeline_json,
                    "raw_files_data": processed_files_json,
                    "template_info": template_info_json,
                    "session_id": agent_session_id,
                    "patient_name": patient_name,
                    "patient_journey_image_url": patient_journey_image_url or "",
                    "patient_journey_image_path": patient_journey_image_path,
                    "indicator_chart_images": json.dumps(indicator_chart_images, ensure_ascii=False),
                    "treatment_gantt_chart_url": treatment_gantt_chart_url or "",
                    "treatment_gantt_chart_path": treatment_gantt_chart_path,
                    "treatment_gantt_data": treatment_gantt_data_json  # æ–°å¢ï¼šæ²»ç–—ç”˜ç‰¹å›¾æ•°æ®ï¼ˆsource_file å·²æ›¿æ¢ä¸ºæ–‡ä»¶åï¼‰
                }

            # æ ¹æ®æ¨¡å¼é€‰æ‹©æ‰§è¡Œä¸åŒçš„ä»»åŠ¡
            mode_name = "Suvalue API" if self._use_suvalue_api else "Local python-pptx"
            workflow_name = "Agentæµç¨‹" if self._use_agent_workflow else "ç›´æ¥LLMè°ƒç”¨"
            logger.info(f"Starting PPT generation task ({mode_name} mode, {workflow_name})")

            # ğŸ†• åˆ¤æ–­æ˜¯å¦ä½¿ç”¨ç›´æ¥LLMè°ƒç”¨æµç¨‹ï¼ˆä»…Suvalue APIæ¨¡å¼æ”¯æŒï¼‰
            if self._use_suvalue_api and not self._use_agent_workflow:
                logger.info("=" * 80)
                logger.info("ä½¿ç”¨ç›´æ¥LLMè°ƒç”¨æµç¨‹ç”ŸæˆPPTï¼ˆç»•è¿‡Agentï¼‰")
                logger.info("=" * 80)

                # 1. ä½¿ç”¨LLMç”ŸæˆPPTæ•°æ®
                ppt_data = self._generate_ppt_data_with_llm(
                    patient_timeline=patient_timeline,
                    raw_files_data=processed_raw_files_data,
                    patient_name=patient_name,
                    patient_journey_image_url=patient_journey_image_url,
                    indicator_chart_images=indicator_chart_images,
                    treatment_gantt_chart_url=treatment_gantt_chart_url,
                    treatment_gantt_data=gantt_data if 'gantt_data' in locals() else None,
                    template_type=2
                )

                if not ppt_data:
                    return {"success": False, "error": "LLMç”ŸæˆPPTæ•°æ®å¤±è´¥"}

                # 2. ç›´æ¥è°ƒç”¨å·¥å…·ç”ŸæˆPPT
                logger.info("è°ƒç”¨SuvalueGeneratePPTToolç”ŸæˆPPT...")
                ppt_tool = SuvalueGeneratePPTTool()
                ppt_info = ppt_tool._run(template_type=2, ppt_data=ppt_data)

                if ppt_info and ppt_info.get("success"):
                    logger.info(f"âœ… ç›´æ¥LLMè°ƒç”¨æµç¨‹æˆåŠŸ: ppt_url={ppt_info.get('ppt_url')}")
                    # æ·»åŠ  treatment_gantt_data å’Œ ppt_data åˆ°è¿”å›ç»“æœ
                    ppt_info["treatment_gantt_data"] = gantt_data if 'gantt_data' in locals() else []
                    ppt_info["ppt_data"] = ppt_data
                    return ppt_info
                else:
                    error_msg = ppt_info.get("error", "PPTç”Ÿæˆå¤±è´¥") if ppt_info else "PPTç”Ÿæˆå¤±è´¥"
                    logger.error(f"âŒ ç›´æ¥LLMè°ƒç”¨æµç¨‹å¤±è´¥: {error_msg}")
                    return {"success": False, "error": error_msg}

            # åŸæœ‰çš„Agentæµç¨‹
            if self._use_suvalue_api:
                # Suvalue API æ¨¡å¼ï¼šå•ç‹¬æ‰§è¡Œç‰¹å®šä»»åŠ¡
                logger.info("Step 1: Executing Suvalue PPT transformation and generation task (Agentæµç¨‹)")
                task = self.transform_and_generate_ppt_task()
                task.interpolate_inputs_and_add_conversation_history(ppt_inputs)
                result = self.suvalue_ppt_data_transformer().execute_task(task)
                logger.info("Suvalue PPT generation completed")
            else:
                # æœ¬åœ°æ¨¡å¼ï¼šå•ç‹¬æ‰§è¡Œç‰¹å®šä»»åŠ¡
                logger.info("Step 1: Executing local PPT slides generation task")
                task = self.generate_ppt_slides_task()
                task.interpolate_inputs_and_add_conversation_history(ppt_inputs)
                result = self.ppt_content_generator().execute_task(task)
                logger.info("Local PPT generation completed")

            # è®°å½•åŸå§‹è¿”å›ç»“æœç”¨äºè°ƒè¯•
            logger.info(f"Crewæ‰§è¡Œç»“æœç±»å‹: {type(result)}")
            logger.info(f"Crewæ‰§è¡Œç»“æœå†…å®¹: {str(result)[:500]}")

            # ä»CrewOutputå¯¹è±¡ä¸­æå–ç»“æœ
            ppt_info = None

            if hasattr(result, 'json_dict') and result.json_dict:
                ppt_info = result.json_dict
                logger.info("ä»CrewOutput.json_dictæå–ç»“æœ")
            elif hasattr(result, 'pydantic') and result.pydantic:
                ppt_info = result.pydantic if isinstance(result.pydantic, dict) else result.pydantic.dict()
                logger.info("ä»CrewOutput.pydanticæå–ç»“æœ")
            elif hasattr(result, 'raw'):
                if isinstance(result.raw, dict):
                    ppt_info = result.raw
                    logger.info("ä»CrewOutput.rawæå–ç»“æœï¼ˆå­—å…¸ï¼‰")
                elif isinstance(result.raw, str):
                    # å…ˆå°è¯•ä»æ–‡æœ¬ä¸­æå–JSONï¼ˆå¤„ç†åŒ…å«Thoughtç­‰éJSONæ–‡æœ¬çš„æƒ…å†µï¼‰
                    json_str = JsonUtils.extract_json_from_text(result.raw)
                    if json_str:
                        logger.info("ä»CrewOutput.rawä¸­æå–åˆ°JSONå­—ç¬¦ä¸²")
                        ppt_info = JsonUtils.safe_parse_json(json_str, debug_prefix="PPT generation")
                        if ppt_info:
                            logger.info("ä»CrewOutput.rawæå–ç»“æœï¼ˆJSONè§£æï¼‰")
                    else:
                        # å¦‚æœæå–ä¸åˆ°JSONï¼Œå°è¯•ast.literal_eval
                        import ast
                        try:
                            ppt_info = ast.literal_eval(result.raw)
                            logger.info("ä»CrewOutput.rawæå–ç»“æœï¼ˆä½¿ç”¨ast.literal_evalï¼‰")
                        except (ValueError, SyntaxError) as e:
                            logger.warning(f"ast.literal_evalå¤±è´¥ä¸”æ— æ³•æå–JSON: {e}")
                            logger.warning(f"åŸå§‹å†…å®¹: {result.raw[:500]}")

            if not ppt_info:
                # æœ€åå°è¯•ä»æ•´ä¸ªresultå­—ç¬¦ä¸²ä¸­æå–JSON
                result_str = str(result)
                json_str = JsonUtils.extract_json_from_text(result_str)
                if json_str:
                    logger.info("ä»resultå­—ç¬¦ä¸²ä¸­æå–åˆ°JSON")
                    ppt_info = JsonUtils.safe_parse_json(json_str, debug_prefix="PPT generation")
                else:
                    logger.warning(f"æ— æ³•ä»resultä¸­æå–JSONï¼ŒåŸå§‹å†…å®¹: {result_str[:500]}")

            if ppt_info and ppt_info.get("success"):
                # æ ¹æ®æ¨¡å¼æ·»åŠ é¢å¤–ä¿¡æ¯
                if not self._use_suvalue_api:
                    # æœ¬åœ°æ¨¡å¼ï¼šæ·»åŠ å›¾ç‰‡URLå’Œè·¯å¾„
                    if patient_journey_image_url:
                        ppt_info["patient_journey_image_url"] = patient_journey_image_url
                        logger.info(f"æ‚£è€…æ—¶é—´æ—…ç¨‹å›¾ç‰‡URLå·²æ·»åŠ åˆ°PPTç»“æœ: {patient_journey_image_url}")
                    if patient_journey_image_path:
                        ppt_info["patient_journey_image_path"] = patient_journey_image_path
                        logger.info(f"æ‚£è€…æ—¶é—´æ—…ç¨‹å›¾ç‰‡æœ¬åœ°è·¯å¾„å·²æ·»åŠ åˆ°PPTç»“æœ: {patient_journey_image_path}")
                    if indicator_chart_images:
                        ppt_info["indicator_chart_images"] = indicator_chart_images
                        logger.info(f"æ ¸å¿ƒæŒ‡æ ‡è¶‹åŠ¿å›¾ç‰‡ä¿¡æ¯å·²æ·»åŠ åˆ°PPTç»“æœ: {len(indicator_chart_images)} ä¸ªå›¾ç‰‡")
                    if treatment_gantt_chart_url:
                        ppt_info["treatment_gantt_chart_url"] = treatment_gantt_chart_url
                        logger.info(f"æ²»ç–—ç”˜ç‰¹å›¾URLå·²æ·»åŠ åˆ°PPTç»“æœ: {treatment_gantt_chart_url}")
                    if treatment_gantt_chart_path:
                        ppt_info["treatment_gantt_chart_path"] = treatment_gantt_chart_path
                        logger.info(f"æ²»ç–—ç”˜ç‰¹å›¾æœ¬åœ°è·¯å¾„å·²æ·»åŠ åˆ°PPTç»“æœ: {treatment_gantt_chart_path}")

                    logger.info(f"Local PPTç”ŸæˆæˆåŠŸ: local_path={ppt_info.get('local_path')}, "
                              f"file_uuid={ppt_info.get('file_uuid')}, qiniu_url={ppt_info.get('qiniu_url')}")
                    if not ppt_info.get('file_uuid'):
                        logger.warning("Local PPTç”ŸæˆæˆåŠŸä½†ç¼ºå°‘file_uuidå­—æ®µï¼ˆå¯èƒ½æœªä¸Šä¼ åˆ°ä¸ƒç‰›äº‘ï¼‰")
                else:
                    # Suvalue APIæ¨¡å¼
                    logger.info(f"Suvalue PPTç”ŸæˆæˆåŠŸ: ppt_url={ppt_info.get('ppt_url')}")

                return ppt_info
            else:
                if ppt_info is None or not ppt_info:
                    error_msg = f"æ— æ³•è§£æCrewè¿”å›ç»“æœã€‚åŸå§‹ç»“æœ: {str(result)[:200]}"
                elif not isinstance(ppt_info, dict):
                    error_msg = f"Crewè¿”å›ç»“æœä¸æ˜¯å­—å…¸ç±»å‹: {type(ppt_info)}, å†…å®¹: {str(ppt_info)[:200]}"
                else:
                    error_msg = ppt_info.get("error", f"PPTç”Ÿæˆå¤±è´¥ä½†æœªæä¾›é”™è¯¯ä¿¡æ¯ã€‚è¿”å›å†…å®¹: {str(ppt_info)[:200]}")

                logger.error(f"PPTç”Ÿæˆå¤±è´¥ ({mode_name} mode): {error_msg}")
                return {"success": False, "error": error_msg}

        except Exception as e:
            mode_name = "Suvalue API" if self._use_suvalue_api else "Local python-pptx"
            logger.error(f"Error in PPT generation ({mode_name} mode): {e}", exc_info=True)
            return {"success": False, "error": str(e)}
