# 输出分块生成 - 解决小输出模型的问题

## 📋 问题场景

### 典型案例

**模型**: GPT-4
**输入限制**: 128,000 tokens ✅
**输出限制**: 4,096 tokens ❌

**问题**:
- 输入数据：50,000 tokens（经过压缩后）✅ 可以输入
- 需要输出：完整PPT JSON，约12,000 tokens ❌ 超过输出限制
- 结果：输出被截断，JSON不完整，无法使用

---

## 💡 解决方案：输出分块生成

### 核心思路

将PPT生成任务拆分成多个子任务，每个子任务生成PPT的一部分，最后合并。

```
完整PPT (12,000 tokens)
    ↓ 拆分
├─ 基本信息 (500 tokens)    ✅
├─ 治疗信息 (2,000 tokens)  ✅
├─ 检查信息 (2,000 tokens)  ✅
├─ 影像资料 (1,500 tokens)  ✅
├─ 时间轴 (1,000 tokens)    ✅
└─ 图表数据 (1,000 tokens)  ✅
    ↓ 合并
完整PPT (8,000 tokens) ✅
```

---

## 🔧 实现细节

### 1. 分块策略

```python
PPT_CHUNKS = {
    'basic_info': {
        'name': '基本信息',
        'fields': ['title', 'patient', 'diag'],
        'priority': 1,
        'estimated_tokens': 500
    },
    'treatments': {
        'name': '治疗信息',
        'fields': ['treatments', 'medications'],
        'priority': 2,
        'estimated_tokens': 2000
    },
    'examinations': {
        'name': '检查信息',
        'fields': ['examinations', 'lab_tests'],
        'priority': 3,
        'estimated_tokens': 2000
    },
    'images': {
        'name': '影像资料',
        'fields': ['images', 'medical_images'],
        'priority': 4,
        'estimated_tokens': 1500
    },
    'timeline': {
        'name': '时间轴',
        'fields': ['timeline', 'events'],
        'priority': 5,
        'estimated_tokens': 1000
    },
    'charts': {
        'name': '图表数据',
        'fields': ['indicators', 'gantt', 'charts'],
        'priority': 6,
        'estimated_tokens': 1000
    }
}
```

### 2. 自动检测

系统会自动检测是否需要分块输出：

```python
# 估算输出大小
estimated_output_size = output_chunked_generator.estimate_output_size(patient_data)

# 检查是否需要分块
use_chunked_output = output_chunked_generator.should_use_chunked_output(
    model_name='gpt-4',
    expected_output_size=estimated_output_size
)

# 判断标准：
# - 如果预期输出 > 安全限制的80%，启用分块
# - GPT-4: 4096 * 0.9 * 0.8 = 2949 tokens
```

### 3. 分块生成流程

```log
====================================================================================================
🔀 启动分块生成模式
====================================================================================================

📦 生成分块 1/6: 基本信息
  ├─ 包含字段: ['title', 'patient', 'diag']
  └─ 预估tokens: 500
  ✅ 分块生成成功

📦 生成分块 2/6: 治疗信息
  ├─ 包含字段: ['treatments', 'medications']
  └─ 预估tokens: 2000
  ✅ 分块生成成功

📦 生成分块 3/6: 检查信息
  ├─ 包含字段: ['examinations', 'lab_tests']
  └─ 预估tokens: 2000
  ✅ 分块生成成功

📦 生成分块 4/6: 影像资料
  ├─ 包含字段: ['images', 'medical_images']
  └─ 预估tokens: 1500
  ✅ 分块生成成功

📦 生成分块 5/6: 时间轴
  ├─ 包含字段: ['timeline', 'events']
  └─ 预估tokens: 1000
  ✅ 分块生成成功

📦 生成分块 6/6: 图表数据
  ├─ 包含字段: ['indicators', 'gantt', 'charts']
  └─ 预估tokens: 1000
  ✅ 分块生成成功

🔗 开始合并所有分块...

====================================================================================================
✅ 分块生成完成！共生成 6 个分块
====================================================================================================
```

---

## 📊 不同模型的策略

### 大输出模型（≥32K tokens）
**示例**: Claude 3 Opus, Gemini 1.5 Pro
**策略**: 通常不需要分块，直接生成
**优势**: 速度快，一次完成

### 中等输出模型（8K-32K tokens）
**示例**: GPT-4 Turbo (4K), Claude 3 Sonnet
**策略**: 根据数据量自动判断
**优势**: 灵活适应

### 小输出模型（<8K tokens）
**示例**: GPT-4 (4K), GPT-3.5 (4K)
**策略**: 强烈建议分块
**优势**: 保证完整性

---

## 🎯 使用方式

### 自动模式（推荐）

系统已集成自动检测，无需手动配置：

```python
# 系统会自动：
# 1. 估算输出大小
# 2. 检查模型限制
# 3. 决定是否分块
# 4. 执行相应策略
```

### 手动模式

如果需要强制使用分块输出：

```python
ppt_data = self._generate_ppt_data_with_llm(
    patient_timeline=patient_timeline,
    raw_files_data=raw_files_data,
    patient_name=patient_name,
    use_chunked_output=True  # 强制使用分块输出
)
```

---

## 📈 性能对比

### 场景：大量患者数据

| 模式 | 输入 | 输出需求 | 结果 | 耗时 |
|------|------|----------|------|------|
| **直接生成** | 50K tokens | 12K tokens | ❌ 截断 | 30s |
| **分块生成** | 50K tokens | 6个分块 | ✅ 完整 | 90s |

**说明**:
- 分块生成耗时更长（需要多次LLM调用）
- 但保证了输出完整性
- 适合输出限制小的模型

---

## ⚙️ 配置选项

### 环境变量

```bash
# .env

# 是否启用输出分块（默认：自动检测）
ENABLE_OUTPUT_CHUNKING=auto  # auto/true/false

# 输出分块阈值（预期输出超过此比例时启用分块）
OUTPUT_CHUNKING_THRESHOLD=0.8  # 80%

# 分块数量（默认：6个分块）
OUTPUT_CHUNK_COUNT=6
```

---

## 🔍 日志示例

### 场景1: 不需要分块

```log
====================================================================================================
🤖 使用LLM直接生成PPT数据（绕过Agent流程）
====================================================================================================
✅ 成功获取模板JSON，长度: 15,234 字符

📊 输出检查:
  ├─ 预期输出: 5,000 tokens
  ├─ 模型限制: 65,535 tokens
  ├─ 安全限制: 58,981 tokens
  └─ 需要分块: 否 ✅

📤 准备调用LLM生成PPT数据...
✅ LLM调用成功，响应长度: 12,345 字符
✅ JSON解析成功
✅ 成功生成PPT数据结构
```

### 场景2: 需要分块

```log
====================================================================================================
🤖 使用LLM直接生成PPT数据（绕过Agent流程）
====================================================================================================
✅ 成功获取模板JSON，长度: 15,234 字符

📊 输出检查:
  ├─ 预期输出: 12,000 tokens
  ├─ 模型限制: 4,096 tokens
  ├─ 安全限制: 3,686 tokens
  └─ 需要分块: 是 ⚠️

====================================================================================================
⚠️ 预期输出较大 (12,000 tokens)，启用分块输出模式
====================================================================================================

====================================================================================================
🔀 启动分块生成模式
====================================================================================================

📦 生成分块 1/6: 基本信息
  ✅ 分块生成成功

📦 生成分块 2/6: 治疗信息
  ✅ 分块生成成功

... (省略其他分块)

🔗 开始合并所有分块...

====================================================================================================
✅ 分块生成完成！共生成 6 个分块
====================================================================================================
```

---

## 🎯 优势总结

### 1. 保证完整性
- ✅ 即使输出限制小，也能生成完整PPT
- ✅ 避免JSON截断问题
- ✅ 每个分块独立验证

### 2. 灵活适应
- ✅ 自动检测模型限制
- ✅ 根据数据量动态调整
- ✅ 支持多种模型

### 3. 可控性强
- ✅ 详细的日志记录
- ✅ 每个分块可单独重试
- ✅ 失败分块不影响其他部分

### 4. 扩展性好
- ✅ 易于添加新的分块类型
- ✅ 可自定义分块策略
- ✅ 支持优先级排序

---

## 📝 注意事项

1. **性能开销**: 分块生成需要多次LLM调用，耗时更长
2. **成本增加**: 多次调用意味着更高的API成本
3. **数据一致性**: 需要确保各分块之间的数据一致性
4. **合并逻辑**: 复杂的数据结构可能需要特殊的合并逻辑

---

## 🚀 未来优化

可选的增强功能：
- [ ] 并行生成多个分块（提高速度）
- [ ] 智能分块大小调整（根据实际输出动态调整）
- [ ] 分块缓存（避免重复生成）
- [ ] 增量更新（只重新生成变化的分块）

---

## 总结

输出分块生成功能解决了小输出模型无法生成完整PPT的问题，通过将任务拆分成多个子任务，保证了输出的完整性。系统已集成自动检测，会根据模型限制和数据量自动决定是否使用分块生成。

**适用场景**:
- ✅ 使用输出限制小的模型（如GPT-4 4K）
- ✅ 需要生成大量数据（如完整PPT）
- ✅ 对输出完整性要求高

**不适用场景**:
- ❌ 使用大输出模型（如Gemini 1.5 Pro 64K）
- ❌ 输出数据量小（<2K tokens）
- ❌ 对响应速度要求极高
