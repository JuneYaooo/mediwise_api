"""
æ£€æŸ¥ç‰¹å®šæ‚£è€…çš„ file_uuid å¯¹åº”å…³ç³»
"""
import json
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker

# æ•°æ®åº“è¿æ¥
DATABASE_URL = "postgresql://mdtadmin:mdtadmin@2025@112.124.15.49:5432/db_mdt"
engine = create_engine(DATABASE_URL)
Session = sessionmaker(bind=engine)

patient_id = "3ae4e400-f8b2-4c9b-b465-9637e06eabcc"

session = Session()

try:
    print("=" * 100)
    print(f"ğŸ” æ£€æŸ¥æ‚£è€…: {patient_id}")
    print("=" * 100)

    # 1. æŸ¥çœ‹ bus_patient_files è¡¨
    print("\n" + "=" * 100)
    print("1ï¸âƒ£ bus_patient_files è¡¨ä¸­çš„æ–‡ä»¶è®°å½•")
    print("=" * 100)

    result = session.execute(text("""
        SELECT
            id,
            file_uuid,
            file_name,
            conversation_id,
            created_at,
            upload_timestamp
        FROM bus_patient_files
        WHERE patient_id = :patient_id
            AND is_deleted = false
        ORDER BY created_at DESC
    """), {'patient_id': patient_id})

    files_data = []
    print(f"\nå…±æ‰¾åˆ° {result.rowcount if hasattr(result, 'rowcount') else '?'} ä¸ªæ–‡ä»¶:")

    for idx, row in enumerate(result, 1):
        file_record = {
            'id': row[0],
            'file_uuid': row[1],
            'file_name': row[2],
            'conversation_id': row[3],
            'created_at': row[4],
            'upload_timestamp': row[5]
        }
        files_data.append(file_record)

        print(f"\n  ğŸ“„ æ–‡ä»¶ {idx}:")
        print(f"    id (ä¸»é”®):        {row[0]}")
        print(f"    file_uuid:        {row[1]}")
        print(f"    file_name:        {row[2]}")
        print(f"    conversation_id:  {row[3]}")
        print(f"    created_at:       {row[4]}")
        print(f"    upload_timestamp: {row[5]}")

    if not files_data:
        print("  âš ï¸ æ²¡æœ‰æ‰¾åˆ°æ–‡ä»¶è®°å½•")
        exit(0)

    # æ”¶é›†æ‰€æœ‰ file_uuid
    all_file_uuids = {f['file_uuid'] for f in files_data}
    print(f"\nğŸ“Š ç»Ÿè®¡: å…± {len(files_data)} ä¸ªæ–‡ä»¶, {len(all_file_uuids)} ä¸ªå”¯ä¸€ file_uuid")

    # 2. æŸ¥çœ‹ bus_patient_structured_data è¡¨
    print("\n" + "=" * 100)
    print("2ï¸âƒ£ bus_patient_structured_data è¡¨ä¸­çš„ç»“æ„åŒ–æ•°æ®")
    print("=" * 100)

    result = session.execute(text("""
        SELECT
            id,
            data_type,
            data_category,
            conversation_id,
            structuredcontent,
            created_at
        FROM bus_patient_structured_data
        WHERE patient_id = :patient_id
            AND is_deleted = false
        ORDER BY created_at DESC
    """), {'patient_id': patient_id})

    structured_data_list = []
    for idx, row in enumerate(result, 1):
        structured_record = {
            'id': row[0],
            'data_type': row[1],
            'data_category': row[2],
            'conversation_id': row[3],
            'structuredcontent': row[4],
            'created_at': row[5]
        }
        structured_data_list.append(structured_record)

        print(f"\n  ğŸ“Š è®°å½• {idx}:")
        print(f"    id:              {row[0]}")
        print(f"    data_type:       {row[1]}")
        print(f"    data_category:   {row[2]}")
        print(f"    conversation_id: {row[3]}")
        print(f"    created_at:      {row[5]}")
        print(f"    content length:  {len(str(row[4])) if row[4] else 0} å­—ç¬¦")

    if not structured_data_list:
        print("  âš ï¸ æ²¡æœ‰æ‰¾åˆ°ç»“æ„åŒ–æ•°æ®")
        exit(0)

    # 3. è¯¦ç»†æ£€æŸ¥ file_uuid å¯¹åº”å…³ç³»
    print("\n" + "=" * 100)
    print("3ï¸âƒ£ file_uuid å¯¹åº”å…³ç³»è¯¦ç»†æ£€æŸ¥")
    print("=" * 100)

    for sd in structured_data_list:
        print(f"\nğŸ” æ£€æŸ¥ {sd['data_type']} (category: {sd['data_category']}):")

        content = sd['structuredcontent']
        if not content:
            print("  âš ï¸ structuredcontent ä¸ºç©º")
            continue

        # æ£€æŸ¥ timeline ç±»å‹
        if sd['data_type'] == 'timeline' and isinstance(content, dict):
            timeline = content.get('timeline', [])
            print(f"  timeline æ¡ç›®æ•°: {len(timeline)}")

            total_items = 0
            items_with_uuid = 0
            matched_uuids = []
            unmatched_uuids_in_content = []
            all_uuids_in_content = set()

            for entry in timeline:
                entry_date = entry.get('date', 'æœªçŸ¥æ—¥æœŸ')
                data_blocks = entry.get('data_blocks', [])

                for block in data_blocks:
                    block_category = block.get('category', 'æœªçŸ¥åˆ†ç±»')
                    items = block.get('items', [])

                    for item in items:
                        total_items += 1
                        item_file_uuid = item.get('file_uuid')

                        if item_file_uuid:
                            items_with_uuid += 1
                            all_uuids_in_content.add(item_file_uuid)

                            if item_file_uuid in all_file_uuids:
                                matched_uuids.append({
                                    'uuid': item_file_uuid,
                                    'date': entry_date,
                                    'category': block_category,
                                    'content': item.get('content', '')[:50]
                                })
                            else:
                                unmatched_uuids_in_content.append({
                                    'uuid': item_file_uuid,
                                    'date': entry_date,
                                    'category': block_category
                                })

            print(f"\n  ğŸ“Š ç»Ÿè®¡:")
            print(f"    æ€» items:              {total_items}")
            print(f"    åŒ…å« file_uuid çš„:     {items_with_uuid} ({items_with_uuid/total_items*100:.1f}% if total_items > 0 else 0)")
            print(f"    å”¯ä¸€ file_uuid:        {len(all_uuids_in_content)}")
            print(f"    åŒ¹é…çš„:                {len(matched_uuids)}")
            print(f"    ä¸åŒ¹é…çš„:              {len(unmatched_uuids_in_content)}")

            if matched_uuids:
                print(f"\n  âœ… åŒ¹é…çš„ file_uuid (å‰5ä¸ª):")
                for match in matched_uuids[:5]:
                    matching_file = next((f for f in files_data if f['file_uuid'] == match['uuid']), None)
                    if matching_file:
                        print(f"    - {match['uuid']}")
                        print(f"      æ–‡ä»¶: {matching_file['file_name']}")
                        print(f"      æ—¥æœŸ: {match['date']}, åˆ†ç±»: {match['category']}")
                        print(f"      å†…å®¹: {match['content']}...")

            if unmatched_uuids_in_content:
                print(f"\n  âŒ ä¸åŒ¹é…çš„ file_uuid (åœ¨ structuredcontent ä¸­ä½†ä¸åœ¨ bus_patient_files ä¸­):")
                for unmatch in unmatched_uuids_in_content[:5]:
                    print(f"    - {unmatch['uuid']}")
                    print(f"      æ—¥æœŸ: {unmatch['date']}, åˆ†ç±»: {unmatch['category']}")

            # æ£€æŸ¥åå‘ï¼šbus_patient_files ä¸­æœ‰ä½† structuredcontent ä¸­æ²¡æœ‰çš„
            missing_in_content = all_file_uuids - all_uuids_in_content
            if missing_in_content:
                print(f"\n  âš ï¸ åœ¨ bus_patient_files ä¸­ä½†ä¸åœ¨ structuredcontent ä¸­çš„ file_uuid:")
                for uuid in missing_in_content:
                    matching_file = next((f for f in files_data if f['file_uuid'] == uuid), None)
                    if matching_file:
                        print(f"    - {uuid}")
                        print(f"      æ–‡ä»¶: {matching_file['file_name']}")
                        print(f"      åˆ›å»ºæ—¶é—´: {matching_file['created_at']}")

        elif sd['data_type'] == 'journey':
            # æ£€æŸ¥ journey ç±»å‹
            content_str = json.dumps(content, ensure_ascii=False)

            matched_count = 0
            for uuid in all_file_uuids:
                if uuid in content_str:
                    matched_count += 1

            print(f"  åŒ¹é…çš„ file_uuid: {matched_count}/{len(all_file_uuids)}")

    # 4. æ€»ç»“
    print("\n" + "=" * 100)
    print("4ï¸âƒ£ è¯Šæ–­ç»“æœ")
    print("=" * 100)

    if matched_uuids and len(matched_uuids) == len(all_file_uuids):
        print("\nâœ… file_uuid å¯¹åº”å…³ç³»æ­£å¸¸ï¼")
        print(f"   æ‰€æœ‰ {len(all_file_uuids)} ä¸ªæ–‡ä»¶çš„ UUID éƒ½åœ¨ structuredcontent ä¸­æ‰¾åˆ°äº†ã€‚")
    elif matched_uuids and len(matched_uuids) < len(all_file_uuids):
        print(f"\nâš ï¸ éƒ¨åˆ† file_uuid å¯¹åº”å…³ç³»æ­£å¸¸")
        print(f"   {len(matched_uuids)}/{len(all_file_uuids)} ä¸ªæ–‡ä»¶çš„ UUID åœ¨ structuredcontent ä¸­")
        print(f"\n   å¯èƒ½åŸå› :")
        print(f"   - æŸäº›æ–‡ä»¶è¿˜æœªå¤„ç†å®Œæˆ")
        print(f"   - LLM æ²¡æœ‰ä¸ºæŸäº›æ•°æ®ç”Ÿæˆ file_uuid")
    else:
        print(f"\nâŒ file_uuid å¯¹åº”å…³ç³»å¼‚å¸¸ï¼")
        print(f"   æ²¡æœ‰æ‰¾åˆ°ä»»ä½•åŒ¹é…çš„ file_uuid")
        print(f"\n   å¯èƒ½åŸå› :")
        print(f"   1. LLM å®Œå…¨æ²¡æœ‰è¾“å‡º file_uuid å­—æ®µ")
        print(f"   2. LLM ç”Ÿæˆäº†å®Œå…¨ä¸åŒçš„ UUID")
        print(f"   3. æ•°æ®è¿˜åœ¨å¤„ç†ä¸­")

    # æ£€æŸ¥æ—¶é—´å·®å¼‚
    if files_data and structured_data_list:
        latest_file_time = max(f['created_at'] for f in files_data)
        latest_data_time = max(sd['created_at'] for sd in structured_data_list)

        print(f"\nâ° æ—¶é—´åˆ†æ:")
        print(f"   æœ€æ–°æ–‡ä»¶ä¸Šä¼ æ—¶é—´:     {latest_file_time}")
        print(f"   æœ€æ–°ç»“æ„åŒ–æ•°æ®æ—¶é—´:   {latest_data_time}")

        if latest_file_time > latest_data_time:
            time_diff = latest_file_time - latest_data_time
            print(f"   âš ï¸ æ–‡ä»¶æ¯”ç»“æ„åŒ–æ•°æ®æ–° {time_diff}")
            print(f"      å¯èƒ½è¿˜åœ¨å¤„ç†ä¸­...")

finally:
    session.close()
